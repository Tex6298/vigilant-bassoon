disarm_id,name,rank,summary,longname,phase_id,tactic_id,framework_id,metatechnique,actortypes,resources_needed,incidents,tactic,responsetype,techniques,incident_ids,tags,object_id,sector_ids,framework_ids
P01,Plan,1,"Envision the desired outcome. Lay out effective ways of achieving it. Communicate the vision, intent, and decisions, focusing on expected results.",P01 - Plan,,,,,,,,,,,,,,,
P02,Prepare,2,"Activities conducted before execution to improve the ability to conduct the action. Examples include: development of the ecosystem needed to support the action: people, network, channels, content etc.",P02 - Prepare,,,,,,,,,,,,,,,
P03,Execute,3,"Run the action, from initial exposure to wrap-up and/or maintaining presence etc.",P03 - Execute,,,,,,,,,,,,,,,
P04,Assess,4,"Evaluate effectiveness of action, for use in future plans ",P04 - Assess,,,,,,,,,,,,,,,
TA01,Plan Strategy,1,"Define the desired end state, i.e. the set of required conditions that defines achievement of all objectives.",TA01 - Plan Strategy,P01,,,,,,,,,,,,,,
TA02,Plan Objectives,2,"Set clearly defined, measurable, and achievable objectives. Achieving objectives ties execution of tactical tasks to reaching the desired end state. There are four primary considerations: 
- Each desired effect should link directly to one or more objectives 
- The effect should be measurable 
- The objective statement should not specify the way and means of accomplishment 
- The effect should be distinguishable from the objective it supports as a condition for success, not as another objective or task.",TA02 - Plan Objectives,P01,,,,,,,,,,,,,,
TA05,Microtarget,8,Target very specific populations of people,TA05 - Microtarget,P02,,,,,,,,,,,,,,
TA06,Develop Content,5,"Create or acquire text, images, and other content",TA06 - Develop Content,P02,,,,,,,,,,,,,,
TA07,Select Channels and Affordances,9,"Selecting platforms and affordances assesses which online or offline platforms and their associated affordances maximize an influence operation’s  ability to reach its target audience. To select the most appropriate platform(s), an operation may  assess the technological affordances including platform algorithms, terms of service, permitted content types, or other attributes that  determine platform usability and accessibility. Selecting platforms includes both choosing platforms on which the operation will publish its own  content and platforms on which the operation will attempt to restrict adversarial content.",TA07 - Select Channels and Affordances,P02,,,,,,,,,,,,,,
TA08,Conduct Pump Priming,10,"Release content on a targetted small scale, prior to general release, including releasing seed. Used for preparation before broader release, and as message honing. Used for preparation before broader release, and as message honing. ",TA08 - Conduct Pump Priming,P03,,,,,,,,,,,,,,
TA09,Deliver Content,11,Release content to general public or larger population,TA09 - Deliver Content,P03,,,,,,,,,,,,,,
TA10,Drive Offline Activity,14,"Move incident/campaign from online to offline. Encouraging users to move from the platform on which they initially viewed operation content and engage in the physical information space or offline world. This may include operation-aligned rallies or protests, radio, newspaper, or billboards. An influence  operation may drive to physical forums to diversify its information channels and facilitate spaces where the target audience can engage with both operation content and like-minded individuals offline.  ",TA10 - Drive Offline Activity,P03,,,,,,,,,,,,,,
TA11,Persist in the Information Environment,15,Persist in the Information Space refers to taking measures that allow an operation to maintain its presence and avoid takedown by an external entity. Techniques in Persist in the Information Space help campaigns operate without detection and appear legitimate to the target audience and platform monitoring services. Influence operations on social media often persist online by varying the type of information  assets and platforms used throughout the campaign.,TA11 - Persist in the Information Environment,P03,,,,,,,,,,,,,,
TA12,Assess Effectiveness,16,"Assess effectiveness of action, for use in future plans ",TA12 - Assess Effectiveness,P04,,,,,,,,,,,,,,
TA13,Target Audience Analysis,3,"Identifying and analyzing the target audience examines target audience member locations,  political affiliations, financial situations, and other attributes that an influence operation may incorporate into its messaging strategy. During this tactic, influence operations may also identify  existing similarities and differences between target audience members to unite like groups and  divide opposing groups. Identifying and analyzing target audience members allows influence operations to tailor  operation strategy and content to their analysis. ",TA13 - Target Audience Analysis,P01,,,,,,,,,,,,,,
TA14,Develop Narratives,4,"The promotion of beneficial master narratives is perhaps the most effective method for achieving long-term strategic narrative dominance. From a """"whole of society"""" perspective the promotion of the society's core master narratives should occupy a central strategic role. From a misinformation campaign / cognitive security perpectve the tactics around master narratives center more precisely on the day-to-day promotion and reinforcement of this messaging. In other words, beneficial, high-coverage master narratives are a central strategic goal and their promotion constitutes an ongoing tactical struggle carried out at a whole-of-society level. Tactically, their promotion covers a broad spectrum of activities both on- and offline.",TA14 - Develop Narratives,P02,,,,,,,,,,,,,,
TA15,Establish Social Assets,6,"Establishing information assets generates messaging tools, including social media accounts,  operation personnel, and organizations, including directly and indirectly managed assets. For assets under their direct control, the operation can add,  change, or remove these assets at will.  
Establishing information assets allows an influence operation to promote messaging directly to  the target audience without navigating through external entities. Many online influence operations create or compromise social media accounts as a primary vector of information  dissemination.",TA15 - Establish Social Assets,P02,,,,,,,,,,,,,,
TA16,Establish Legitimacy,7,Establish assets that create trust,TA16 - Establish Legitimacy,P02,,,,,,,,,,,,,,
TA17,Maximize Exposure,12,"Maximize exposure of the target audience to incident/campaign content via flooding, amplifying, and cross-posting.",TA17 - Maximize Exposure,P03,,,,,,,,,,,,,,
TA18,Drive Online Harms,13,"Actions taken by an influence operation to harm their opponents in online spaces through harassment, suppression, releasing private information, and controlling the information space through offensive cyberspace operations. ",TA18 - Drive Online Harms,P03,,,,,,,,,,,,,,
T0002,Facilitate State Propaganda,,Organize citizens around pro-state messaging. Coordinate paid or volunteer groups to push state propaganda.,T0002 - Facilitate State Propaganda,,TA02,,,,,,,,,,,,,
T0003,Leverage Existing Narratives,,"Use or adapt existing narrative themes, where narratives are the baseline stories of a target audience. Narratives form the bedrock of our worldviews. New information is understood through a process firmly grounded in this bedrock. If new information is not consitent with the prevailing narratives of an audience, it will be ignored. Effective campaigns will frame their misinformation in the context of these narratives. Highly effective campaigns will make extensive use of audience-appropriate archetypes and meta-narratives throughout their content creation and amplifiction practices. ",T0003 - Leverage Existing Narratives,,TA14,,,,,,,,,,,,,
T0004,Develop Competing Narratives,,"Advance competing narratives connected to same issue ie: on one hand deny incident while at same time expresses dismiss. Suppressing or discouraging narratives already spreading requires an alternative. The most simple set of narrative techniques in response would be the construction and promotion of contradictory alternatives centered on denial, deflection, dismissal, counter-charges, excessive standards of proof, bias in prohibition or enforcement, and so on. These competing narratives allow loyalists cover, but are less compelling to opponents and fence-sitters than campaigns built around existing narratives or highly explanatory master narratives. Competing narratives, as such, are especially useful in the ""firehose of misinformation"" approach.",T0004 - Develop Competing Narratives,,TA14,,,,,,,,,,,,,
T0007,Create Inauthentic Social Media Pages and Groups,,"Create key social engineering assets needed to amplify content, manipulate algorithms, fool public and/or specific incident/campaign targets. Computational propaganda depends substantially on false perceptions of credibility and acceptance. By creating fake users and groups with a variety of interests and commitments, attackers can ensure that their messages both come from trusted sources and appear more widely adopted than they actually are.",T0007 - Create Inauthentic Social Media Pages and Groups,,TA15,,,,,,,,,,,,,
T0009,Create fake experts,,"Stories planted or promoted in computational propaganda operations often make use of experts fabricated from whole cloth, sometimes specifically for the story itself. ",T0009 - Create fake experts,,TA16,,,,,,,,,,,,,
T0009.001,Utilize Academic/Pseudoscientific Justifications,,Utilize Academic/Pseudoscientific Justifications,Utilize Academic/Pseudoscientific Justifications - ,,TA16,,,,,,,,,,,,,
T0010,Cultivate ignorant agents,,"Cultivate propagandists for a cause, the goals of which are not fully comprehended, and who are used cynically by the leaders of the cause. Independent actors use social media and specialised web sites to strategically reinforce and spread messages compatible with their own. Their networks are infiltrated and used by state media disinformation organisations to amplify the state’s own disinformation strategies against target populations. Many are traffickers in conspiracy theories or hoaxes, unified by a suspicion of Western governments and mainstream media. Their narratives, which appeal to leftists hostile to globalism and military intervention and nationalists against immigration, are frequently infiltrated and shaped by state-controlled trolls and altered news items from agencies such as RT and Sputnik. Also know as ""useful idiots"" or ""unwitting agents"".",T0010 - Cultivate ignorant agents,,TA15,,,,,,,,,,,,,
T0011,Compromise legitimate accounts,,Hack or take over legimate accounts to distribute misinformation or damaging content.,T0011 - Compromise legitimate accounts,,TA16,,,,,,,,,,,,,
T0013,Create inauthentic websites,,"Create media assets to support inauthentic organizations (e.g. think tank), people (e.g. experts) and/or serve as sites to distribute malware/launch phishing operations.",T0013 - Create inauthentic websites,,TA15,,,,,,,,,,,,,
T0014,Prepare fundraising campaigns,,"Fundraising campaigns refer to an influence operation’s systematic effort to seek financial  support for a charity, cause, or other enterprise using online activities that further promote  operation information pathways while raising a profit. Many influence operations have engaged  in crowdfunding services on platforms including Tipee, Patreon, and GoFundMe. An operation  may use its previously prepared fundraising campaigns (see: Develop Information Pathways) to  promote operation messaging while raising money to support its activities.  ",T0014 - Prepare fundraising campaigns,,TA15,,,,,,,,,,,,,
T0014.001,Raise funds from malign actors,,"Raising funds from malign actors may include contributions from foreign agents, cutouts or proxies, shell companies, dark money groups, etc. ",Raise funds from malign actors - ,,TA15,,,,,,,,,,,,,
T0014.002,Raise funds from ignorant agents,,"Raising funds from ignorant agents may include scams, donations intended for one stated purpose but then used for another, etc. ",Raise funds from ignorant agents - ,,TA15,,,,,,,,,,,,,
T0015,Create hashtags and search artifacts,,"Create one or more hashtags and/or hashtag groups. Many incident-based campaigns will create hashtags to promote their fabricated event. Creating a hashtag for an incident can have two important effects: 1. Create a perception of reality around an event. Certainly only ""real"" events would be discussed in a hashtag. After all, the event has a name!, and 2. Publicize the story more widely through trending lists and search behavior. Asset needed to direct/control/manage ""conversation"" connected to launching new incident/campaign with new hashtag for applicable social media sites). ",T0015 - Create hashtags and search artifacts,,TA06,,,,,,,,,,,,,
T0016,Create Clickbait,,"Create attention grabbing headlines (outrage, doubt, humor) required to drive traffic & engagement. This is a key asset.",T0016 - Create Clickbait,,TA05,,,,,,,,,,,,,
T0017,Conduct fundraising,,"Fundraising campaigns refer to an influence operation’s systematic effort to seek financial  support for a charity, cause, or other enterprise using online activities that further promote  operation information pathways while raising a profit. Many influence operations have engaged  in crowdfunding services166 on platforms including Tipee, Patreon, and GoFundMe. An operation  may use its previously prepared fundraising campaigns to promote operation messaging while raising money to support its activities.  ",T0017 - Conduct fundraising,,TA10,,,,,,,,,,,,,
T0017.001,Conduct Crowdfunding Campaigns,,"An influence operation may Conduct Crowdfunding Campaigns on platforms such as GoFundMe, GiveSendGo, Tipeee, Patreon, etc.",Conduct Crowdfunding Campaigns - ,,TA10,,,,,,,,,,,,,
T0018,Purchase Targeted Advertisements,,Create or fund advertisements targeted at specific populations,T0018 - Purchase Targeted Advertisements,,TA05,,,,,,,,,,,,,
T0019,Generate information pollution,,"Flood social channels; drive traffic/engagement to all assets; create aura/sense/perception of pervasiveness/consensus (for or against or both simultaneously) of an issue or topic. ""Nothing is true, but everything is possible."" Akin to astroturfing campaign.",T0019 - Generate information pollution,,TA06,,,,,,,,,,,,,
T0019.001,Create fake research,,"Create fake academic research. Example: fake social science research is often aimed at hot-button social issues such as gender, race and sexuality. Fake science research can target Climate Science debate or pseudoscience like anti-vaxx",Create fake research - ,,TA06,,,,,,,,,,,,,
T0019.002,Hijack Hashtags,,"Hashtag hijacking occurs when users “[use] a trending hashtag to promote topics that are substantially different from its recent context” (VanDam and Tan, 2016) or “to promote one’s own social media agenda” (Darius and Stephany, 2019).",Hijack Hashtags - ,,TA06,,,,,,,,,,,,,
T0020,Trial content,,"Iteratively test incident performance (messages, content etc), e.g. A/B test headline/content enagagement metrics; website and/or funding campaign conversion rates",T0020 - Trial content,,TA08,,,,,,,,,,,,,
T0022,Leverage Conspiracy Theory Narratives,,"""Conspiracy narratives"" appeal to the human desire for explanatory order, by invoking the participation of poweful (often sinister) actors in pursuit of their own political goals. These narratives are especially appealing when an audience is low-information, marginalized or otherwise inclined to reject the prevailing explanation. Conspiracy narratives are an important component of the ""firehose of falsehoods"" model. ",T0022 - Leverage Conspiracy Theory Narratives,,TA14,,,,,,,,,,,,,
T0022.001,Amplify Existing Conspiracy Theory Narratives,,"An influence operation may amplify an existing conspiracy theory narrative that aligns with its incident or campaign goals. By amplifying existing conspiracy theory narratives, operators can leverage the power of the existing communities that support and propagate those theories without needing to expend resources creating new narratives or building momentum and buy in around new narratives. ",Amplify Existing Conspiracy Theory Narratives - ,,TA14,,,,,,,,,,,,,
T0022.002,Develop Original Conspiracy Theory Narratives,,"While this requires more resources than amplifying existing conspiracy theory narratives, an influence operation may develop original conspiracy theory narratives in order to achieve greater control and alignment over the narrative and their campaign goals. Prominent examples include the USSR's Operation INFEKTION disinformation campaign run by the KGB in the 1980s to plant the idea that the United States had invented HIV/AIDS as part of a biological weapons research project at Fort Detrick, Maryland. More recently, Fort Detrick featured prominently in a new conspiracy theory narratives around the origins of the COVID-19 outbreak and pandemic. ",Develop Original Conspiracy Theory Narratives - ,,TA14,,,,,,,,,,,,,
T0023,Distort facts,,"Change, twist, or exaggerate existing facts to construct a narrative that differs from reality. Examples: images and ideas can be distorted by being placed in an improper content",T0023 - Distort facts,,TA06,,,,,,,,,,,,,
T0023.001,Reframe Context,,"Reframing context refers to removing an event from its surrounding context to distort its  intended meaning. Rather than deny that an event occurred, reframing context frames an event in  a manner that may lead the target audience to draw a different conclusion about its intentions. ",Reframe Context - ,,TA06,,,,,,,,,,,,,
T0023.002,Edit Open-Source Content,,"An influence operation may edit open-source content, such as collaborative blogs or  encyclopedias, to promote its narratives on outlets with existing credibility and audiences. Editing open-source content may allow an operation to post content on platforms without  dedicating resources to the creation and maintenance of its own assets. ",Edit Open-Source Content - ,,TA06,,,,,,,,,,,,,
T0029,Online polls,,"Create fake online polls, or manipulate existing online polls. Data gathering tactic to target those who engage, and potentially their networks of friends/followers as well",T0029 - Online polls,,TA07,,,,,,,,,,,,,
T0039 ,Bait legitimate influencers,,"Credibility in a social media environment is often a function of the size of a user's network. ""Influencers"" are so-called because of their reach, typically understood as: 1) the size of their network (i.e. the number of followers, perhaps weighted by their own influence); and 2) The rate at which their comments are re-circulated (these two metrics are related). Add traditional media players at all levels of credibility and professionalism to this, and the number of potential influencial carriers available for unwitting amplification becomes substantial. By targeting high-influence people and organizations in all types of media with narratives and content engineered to appeal their emotional or ideological drivers, influence campaigns are able to add perceived credibility to their messaging via saturation and adoption by trusted agents such as celebrities, journalists and local leaders.",T0039  - Bait legitimate influencers,,TA08,,,,,,,,,,,,,
T0040,Demand insurmountable proof,,"Campaigns often leverage tactical and informational asymmetries on the threat surface, as seen in the Distort and Deny strategies, and the ""firehose of misinformation"". Specifically, conspiracy theorists can be repeatedly wrong, but advocates of the truth need to be perfect. By constantly escalating demands for proof, propagandists can effectively leverage this asymmetry while also priming its future use, often with an even greater asymmetric advantage. The conspiracist is offered freer rein for a broader range of ""questions"" while the truth teller is burdened with higher and higher standards of proof.",T0040 - Demand insurmountable proof,,TA14,,,,,,,,,,,,,
T0042,Seed Kernel of truth,,"Wrap lies or altered context/facts around truths. Influence campaigns pursue a variety of objectives with respect to target audiences, prominent among them: 1. undermine a narrative commonly referenced in the target audience; or 2. promote a narrative less common in the target audience, but preferred by the attacker. In both cases, the attacker is presented with a heavy lift. They must change the relative importance of various narratives in the interpretation of events, despite contrary tendencies. When messaging makes use of factual reporting to promote these adjustments in the narrative space, they are less likely to be dismissed out of hand; when messaging can juxtapose a (factual) truth about current affairs with the (abstract) truth explicated in these narratives, propagandists can undermine or promote them selectively. Context matters.",T0042 - Seed Kernel of truth,,TA08,,,,,,,,,,,,,
T0043,Chat apps,,"Direct messaging via chat app is an increasing method of delivery. These messages are often automated and new delivery and storage methods make them anonymous, viral, and ephemeral. This is a difficult space to monitor, but also a difficult space to build acclaim or notoriety.",T0043 - Chat apps,,TA07,,,,,,,,,,,,,
T0043.001,Use Encrypted Chat Apps,,"Examples include Signal, WhatsApp, Discord, Wire, etc.",Use Encrypted Chat Apps - ,,TA07,,,,,,,,,,,,,
T0043.002,Use Unencrypted Chats Apps,,"Examples include SMS, etc.",Use Unencrypted Chats Apps - ,,TA07,,,,,,,,,,,,,
T0044,Seed distortions,,"Try a wide variety of messages in the early hours surrounding an incident or event, to give a misleading account or impression. ",T0044 - Seed distortions,,TA08,,,,,,,,,,,,,
T0045,Use fake experts,,"Use the fake experts that were set up during Establish Legitimacy. Pseudo-experts are disposable assets that often appear once and then disappear. Give ""credility"" to misinformation. Take advantage of credential bias",T0045 - Use fake experts,,TA08,,,,,,,,,,,,,
T0046,Use Search Engine Optimization,,"Manipulate content engagement metrics (ie: Reddit & Twitter) to influence/impact news search results (e.g. Google), also elevates RT & Sputnik headline into Google news alert emails. aka ""Black-hat SEO"" ",T0046 - Use Search Engine Optimization,,TA08,,,,,,,,,,,,,
T0047,Censor social media as a political force,,Use political influence or the power of state to stop critical social media comments. Government requested/driven content take downs (see Google Transperancy reports).,T0047 - Censor social media as a political force,,TA18,,,,,,,,,,,,,
T0048,Harass,,"Threatening or harassing believers of opposing narratives refers to the use of intimidation  techniques, including cyberbullying and doxing, to discourage opponents from voicing their  dissent. An influence operation may threaten or harass believers of the opposing narratives to  deter individuals from posting or proliferating conflicting content.  ",T0048 - Harass,,TA18,,,,,,,,,,,,,
T0048.001,"Boycott/""Cancel"" Opponents",,"Cancel culture refers to the phenomenon in which individuals collectively refrain from  supporting an individual, organization, business, or other entity, usually following a real or  falsified controversy. An influence operation may exploit cancel culture by emphasizing an  adversary’s problematic or disputed behavior and presenting its own content as an alternative. ","Boycott/""Cancel"" Opponents - ",,TA18,,,,,,,,,,,,,
T0048.002,Harass People Based on Identities,,"Examples include social identities like gender, sexuality, race, ethnicity, religion, ability, nationality, etc. as well as roles and occupations like journalist or activist.",Harass People Based on Identities - ,,TA18,,,,,,,,,,,,,
T0048.003,Threaten to Dox,,"Doxing refers to online harassment in which individuals publicly release private information  about another individual, including names, addresses, employment information, pictures, family  members, and other sensitive information. An influence operation may dox its opposition to  encourage individuals aligned with operation narratives to harass the doxed individuals  themselves or otherwise discourage the doxed individuals from posting or proliferating  conflicting content. ",Threaten to Dox - ,,TA18,,,,,,,,,,,,,
T0048.004,Dox,,"Doxing refers to online harassment in which individuals publicly release private information  about another individual, including names, addresses, employment information, pictures, family  members, and other sensitive information. An influence operation may dox its opposition to  encourage individuals aligned with operation narratives to harass the doxed individuals  themselves or otherwise discourage the doxed individuals from posting or proliferating  conflicting content. ",Dox - ,,TA18,,,,,,,,,,,,,
T0049,Flooding the Information Space,,Flooding and/or mobbing social media channels feeds and/or hashtag with excessive volume of content to control/shape online conversations and/or drown out opposing points of view. Bots and/or patriotic trolls are effective tools to acheive this effect.,T0049 - Flooding the Information Space,,TA17,,,,,,,,,,,,,
T0049.001,Trolls amplify and manipulate,,"Use trolls to amplify narratives and/or manipulate narratives. Fake profiles/sockpuppets operating to support individuals/narratives from the entire political spectrum (left/right binary). Operating with increased emphasis on promoting local content and promoting real Twitter users generating their own, often divisive political content, as it's easier to amplify existing content than create new/original content. Trolls operate where ever there's a socially divisive issue (issues that can/are be politicized).",Trolls amplify and manipulate - ,,TA17,,,,,,,,,,,,,
T0049.002,Hijack existing hashtag,,Take over an existing hashtag to drive exposure.,Hijack existing hashtag - ,,TA17,,,,,,,,,,,,,
T0049.003,Bots Amplify via Automated Forwarding and Reposting,,"Automated forwarding and reposting refer to the proliferation of operation content using  automated means, such as artificial intelligence or social media bots. An influence operation may  use automated activity to increase content exposure without dedicating the resources, including  personnel and time, traditionally required to forward and repost content. 
Use bots to amplify narratives above algorithm thresholds. Bots are automated/programmed profiles designed to amplify content (ie: automatically retweet or like) and give appearance it's more ""popular"" than it is. They can operate as a network, to function in a coordinated/orchestrated manner. In some cases (more so now) they are an inexpensive/disposable assets used for minimal deployment as bot detection tools improve and platforms are more responsive.",Bots Amplify via Automated Forwarding and Reposting - ,,TA17,,,,,,,,,,,,,
T0049.004,Utilize Spamoflauge,,"Spamoflauge refers to the practice of disguising spam messages as legitimate. Spam refers to  the use of electronic messaging systems to send out unrequested or unwanted messages in bulk.  Simple methods of spamoflauge include replacing letters with numbers to fool keyword-based  email spam filters, for example, ""you've w0n our jackp0t!"". Spamoflauge may extend to more complex techniques such as modifying the grammar or word choice of the language, casting  messages as images which spam detectors cannot automatically read, or encapsulating messages  in password protected attachments, such as .pdf or .zip files. Influence operations may use spamoflauge to avoid spam filtering systems and increase the likelihood of the target audience  receiving operation messaging. ",Utilize Spamoflauge - ,,TA17,,,,,,,,,,,,,
T0049.005,Conduct Swarming,,"Swarming refers to the coordinated use of accounts to overwhelm the information space with  operation content. Unlike information flooding, swarming centers exclusively around a specific  event or actor rather than a general narrative. Swarming relies on “horizontal communication”  between information assets rather than a top-down, vertical command-and-control approach. ",Conduct Swarming - ,,TA17,,,,,,,,,,,,,
T0049.006,Conduct Keyword Squatting,,"Keyword squatting refers to the creation of online content, such as websites, articles, or social  media accounts, around a specific search engine-optimized term to overwhelm the search results  of that term. An influence may keyword squat to increase content exposure to target audience  members who query the exploited term in a search engine and manipulate the narrative around  the term.  ",Conduct Keyword Squatting - ,,TA17,,,,,,,,,,,,,
T0049.007,Inauthentic Sites Amplify News and Narratives,,"Inauthentic sites circulate cross-post stories and amplify narratives. Often these sites have no masthead, bylines or attribution.",Inauthentic Sites Amplify News and Narratives - ,,TA17,,,,,,,,,,,,,
T0057,Organize Events,,"Coordinate and promote real-world events across media platforms, e.g. rallies, protests, gatherings in support of incident narratives.",T0057 - Organize Events,,TA10,,,,,,,,,,,,,
T0057.001,Pay for Physical Action,,"Paying for physical action occurs when an influence operation pays individuals to act in the  physical realm. An influence operation may pay for physical action to create specific situations  and frame them in a way that supports operation narratives, for example, paying a group of  people to burn a car to later post an image of the burning car and frame it as an act of protest. ",Pay for Physical Action - ,,TA10,,,,,,,,,,,,,
T0057.002,Conduct Symbolic Action,,"Symbolic action refers to activities specifically intended to advance an operation’s narrative by  signaling something to the audience, for example, a military parade supporting a state’s narrative  of military superiority. An influence operation may use symbolic action to create falsified  evidence supporting operation narratives in the physical information space.  ",Conduct Symbolic Action - ,,TA10,,,,,,,,,,,,,
T0059,Play the long game,,Play the long game refers to two phenomena: 1. To plan messaging and allow it to grow organically without conducting your own amplification. This is methodical and slow and requires years for the message to take hold 2. To develop a series of seemingly disconnected messaging narratives that eventually combine into a new narrative.,T0059 - Play the long game,,TA11,,,,,,,,,,,,,
T0060,Continue to Amplify,,continue narrative or message amplification after the main incident work has finished,T0060 - Continue to Amplify,,TA11,,,,,,,,,,,,,
T0061,Sell Merchandise,,Sell mechandise refers to getting the message or narrative into physical space in the offline world while making money,T0061 - Sell Merchandise,,TA10,,,,,,,,,,,,,
T0065,Prepare Physical Broadcast Capabilities,,"Create or coopt broadcast capabilities (e.g. TV, radio etc).",T0065 - Prepare Physical Broadcast Capabilities,,TA15,,,,,,,,,,,,,
T0066,Degrade Adversary,,Plan to degrade an adversary’s image or ability to act. This could include preparation and use of harmful information about the adversary’s actions or reputation.,T0066 - Degrade Adversary,,TA02,,,,,,,,,,,,,
T0068,Respond to Breaking News Event or Active Crisis,,"Media attention on a story or event is heightened during a breaking news event, where unclear facts and incomplete information increase speculation, rumors, and conspiracy theories, which are all vulnerable to manipulation. ",T0068 - Respond to Breaking News Event or Active Crisis,,TA14,,,,,,,,,,,,,
T0072,Segment Audiences,,"Create audience segmentations by features of interest to the influence campaign, including political affiliation, geographic location, income, demographics, and psychographics. ",T0072 - Segment Audiences,,TA13,,,,,,,,,,,,,
T0072.001,Geographic Segmentation,,"An influence operation may target populations in a specific geographic location, such as a  region, state, or city. An influence operation may use geographic segmentation to Create  Localized Content (see: Establish Legitimacy).  ",Geographic Segmentation - ,,TA13,,,,,,,,,,,,,
T0072.002,Demographic Segmentation,,"An influence operation may target populations based on demographic segmentation, including  age, gender, and income. Demographic segmentation may be useful for influence operations  aiming to change state policies that affect a specific population sector. For example, an influence  operation attempting to influence Medicare funding in the United States would likely target U.S.  voters over 65 years of age. ",Demographic Segmentation - ,,TA13,,,,,,,,,,,,,
T0072.003,Economic Segmentation,,"An influence operation may target populations based on their income bracket, wealth, or other  financial or economic division. ",Economic Segmentation - ,,TA13,,,,,,,,,,,,,
T0072.004,Psychographic Segmentation,,"An influence operation may target populations based on psychographic segmentation, which uses  audience values and decision-making processes. An operation may individually gather  psychographic data with its own surveys or collection tools or externally purchase data from  social media companies or online surveys, such as personality quizzes.  ",Psychographic Segmentation - ,,TA13,,,,,,,,,,,,,
T0072.005,Political Segmentation,,"An influence operation may target populations based on their political affiliations, especially  when aiming to manipulate voting or change policy.",Political Segmentation - ,,TA13,,,,,,,,,,,,,
T0073,Determine Target Audiences,,Determining the target audiences (segments of the population) who will receive campaign narratives and artifacts intended to achieve the strategic ends.,T0073 - Determine Target Audiences,,TA01,,,,,,,,,,,,,
T0074,Determine Strategic Ends,,"Determining the campaigns goals or objectives. Examples include achieving achieving geopolitical advantage like undermining trust in an adversary, gaining domestic political advantage, achieving financial gain, or attaining a policy change, ",T0074 - Determine Strategic Ends,,TA01,,,,,,,,,,,,,
T0075,Dismiss,,Push back against criticism by dismissing your critics. This might be arguing that the critics use a different standard for you than with other actors or themselves; or arguing that their criticism is biased.,T0075 - Dismiss,,TA02,,,,,,,,,,,,,
T0075.001,Discredit Credible Sources,,"Plan to delegitimize the media landscape and degrade public trust in reporting, by discrediting credible sources. This makes it easier to promote influence operation content.",Discredit Credible Sources - ,,TA02,,,,,,,,,,,,,
T0076,Distort,,"Twist the narrative. Take information, or artifacts like images, and change the framing around them.",T0076 - Distort,,TA02,,,,,,,,,,,,,
T0077,Distract,,"Shift attention to a different narrative or actor, for instance by accusing critics of the same activity that they’ve accused you of (e.g. police brutality).",T0077 - Distract,,TA02,,,,,,,,,,,,,
T0078,Dismay,,"Threaten the critic or narrator of events. For instance, threaten journalists or news outlets reporting on a story.",T0078 - Dismay,,TA02,,,,,,,,,,,,,
T0079,Divide,,"Create conflict between subgroups, to widen divisions in a community",T0079 - Divide,,TA02,,,,,,,,,,,,,
T0080,Map Target Audience Information Environment,,"Mapping the target audience information environment analyzes the information space itself,  including social media analytics, web traffic, and media surveys. Mapping the information  environment may help the influence operation determine the most realistic and popular  information channels to reach its target audience. 
Mapping the target audience information environment aids influence operations in determining  the most vulnerable areas of the information space to target with messaging.",T0080 - Map Target Audience Information Environment,,TA13,,,,,,,,,,,,,
T0080.001,Monitor Social Media Analytics,,"An influence operation may use social media analytics to determine which factors will increase  the operation content’s exposure to its target audience on social media platforms, including  views, interactions, and sentiment relating to topics and content types. The social media platform  itself or a third-party tool may collect the metrics.  ",Monitor Social Media Analytics - ,,TA13,,,,,,,,,,,,,
T0080.002,Evaluate Media Surveys,,"An influence operation may evaluate its own or third-party media surveys to determine what type  of content appeals to its target audience. Media surveys may provide insight into an audience’s  political views, social class, general interests, or other indicators used to tailor operation messaging to its target audience.",Evaluate Media Surveys - ,,TA13,,,,,,,,,,,,,
T0080.003,Identify Trending Topics/Hashtags,,An influence operation may identify trending hashtags on social media platforms for later use in  boosting operation content. A hashtag40 refers to a word or phrase preceded by the hash symbol  (#) on social media used to identify messages and posts relating to a specific topic. All public  posts that use the same hashtag are aggregated onto a centralized page dedicated to the word or  phrase and sorted either chronologically or by popularity. ,Identify Trending Topics/Hashtags - ,,TA13,,,,,,,,,,,,,
T0080.004,Conduct Web Traffic Analysis,,"An influence operation may conduct web traffic analysis to determine which search engines,  keywords, websites, and advertisements gain the most traction with its target audience.",Conduct Web Traffic Analysis - ,,TA13,,,,,,,,,,,,,
T0080.005,Assess Degree/Type of Media Access,,"An influence operation may survey a target audience’s Internet availability and degree of media  freedom to determine which target audience members will have access to operation content and  on which platforms. An operation may face more difficulty targeting an information  environment with heavy restrictions and media control than an environment with independent  media, freedom of speech and of the press, and individual liberties. ",Assess Degree/Type of Media Access - ,,TA13,,,,,,,,,,,,,
T0081,Identify Social and Technical Vulnerabilities,,"Identifying social and technical vulnerabilities determines weaknesses within the target audience  information environment for later exploitation. Vulnerabilities include decisive political issues,  weak cybersecurity infrastructure, search engine data voids, and other technical and non technical weaknesses in the target information environment.  
Identifying social and technical vulnerabilities facilitates the later exploitation of the identified  weaknesses to advance operation objectives. ",T0081 - Identify Social and Technical Vulnerabilities,,TA13,,,,,,,,,,,,,
T0081.001,Find Echo Chambers,,"Find or plan to create areas (social media groups, search term groups, hashtag groups etc) where individuals only engage with people they agree with. ",Find Echo Chambers - ,,TA13,,,,,,,,,,,,,
T0081.002,Identify Data Voids,,"A data void refers to a word or phrase that results in little, manipulative, or low-quality search  engine data. Data voids are hard to detect and relatively harmless until exploited by an entity  aiming to quickly proliferate false or misleading information during a phenomenon that causes a  high number of individuals to query the term or phrase. In the Plan phase, an influence operation  may identify data voids for later exploitation in the operation.  
A 2019 report by Michael Golebiewski identifies five types of data voids. (1) “Breaking news”  data voids occur when a keyword gains popularity during a short period of time, allowing an  influence operation to publish false content before legitimate news outlets have an opportunity to  publish relevant information. (2) An influence operation may create a “strategic new terms” data  void by creating their own terms and publishing information online before promoting their  keyword to the target audience. (3) An influence operation may publish content on “outdated  terms” that have decreased in popularity, capitalizing on most search engines’ preferences for  recency. (4) “Fragmented concepts” data voids separate connections between similar ideas,  isolating segment queries to distinct search engine results. (5) An influence operation may use  “problematic queries” that previously resulted in disturbing or inappropriate content to promote  messaging until mainstream media recontextualizes the term.  ",Identify Data Voids - ,,TA13,,,,,,,,,,,,,
T0081.003,Identify Existing Prejudices,,"An influence operation may exploit existing racial, religious, demographic, or social prejudices to further polarize its target audience from the rest of the public.",Identify Existing Prejudices - ,,TA13,,,,,,,,,,,,,
T0081.004,Identify Existing Fissures,,"An influence operation may identify existing fissures to pit target populations against one  another or facilitate a “divide-and-conquer"" approach to tailor operation narratives along the  divides.",Identify Existing Fissures - ,,TA13,,,,,,,,,,,,,
T0081.005,Identify Existing Conspiracy Narratives/Suspicions,,An influence operation may assess preexisting conspiracy theories or suspicions in a population  to identify existing narratives that support operational objectives.  ,Identify Existing Conspiracy Narratives/Suspicions - ,,TA13,,,,,,,,,,,,,
T0081.006,Identify Wedge Issues,,"A wedge issue is a divisive political issue, usually concerning a social phenomenon, that  divides individuals along a defined line. An influence operation may exploit wedge issues by  intentionally polarizing the public along the wedge issue line and encouraging opposition  between factions.",Identify Wedge Issues - ,,TA13,,,,,,,,,,,,,
T0081.007,Identify Target Audience Adversaries,,"An influence operation may identify or create a real or imaginary adversary to center operation  narratives against. A real adversary may include certain politicians or political parties while  imaginary adversaries may include falsified “deep state”62 actors that, according to conspiracies,  run the state behind public view. ",Identify Target Audience Adversaries - ,,TA13,,,,,,,,,,,,,
T0081.008,Identify Media System Vulnerabilities,,"An influence operation may exploit existing weaknesses in a target’s media system. These  weaknesses may include existing biases among media agencies, vulnerability to false news  agencies on social media, or existing distrust of traditional media sources. An existing distrust  among the public in the media system’s credibility holds high potential for exploitation by an  influence operation when establishing alternative news agencies to spread operation content. ",Identify Media System Vulnerabilities - ,,TA13,,,,,,,,,,,,,
T0082,Develop New Narratives,,"Actors may develop new narratives to further strategic or tactical goals, especially when existing narratives adequately align with the campaign goals. New narratives provide more control in terms of crafting the message to achieve specific goals. However, new narratives may require more effort to disseminate than adapting or adopting existing narratives. ",T0082 - Develop New Narratives,,TA14,,,,,,,,,,,,,
T0083,Integrate Target Audience Vulnerabilities into Narrative,,"An influence operation may seek to exploit the preexisting weaknesses, fears, and enemies of the  target audience for integration into the operation’s narratives and overall strategy. Integrating  existing vulnerabilities into the operational approach conserves resources by exploiting already  weak areas of the target information environment instead of forcing the operation to create new  vulnerabilities in the environment.",T0083 - Integrate Target Audience Vulnerabilities into Narrative,,TA14,,,,,,,,,,,,,
T0084,Reuse Existing Content,,When an operation recycles content from its own previous  operations or plagiarizes from external operations. An operation may launder information to  conserve resources that would have otherwise been utilized to develop new content. ,T0084 - Reuse Existing Content,,TA06,,,,,,,,,,,,,
T0084.001,Use Copypasta,,"Copypasta refers to a piece of text that has been copied and pasted multiple times across various online platforms. A copypasta’s final form may differ from its original source text as users add, delete, or otherwise edit the content as they repost the text. ",Use Copypasta - ,,TA06,,,,,,,,,,,,,
T0084.002,Plagiarize Content,,An influence operation may take content from other sources without proper attribution. This content may be either misinformation content shared by others without malicious intent but now leveraged by the campaign as disinformation or disinformation content from other sources. ,Plagiarize Content - ,,TA06,,,,,,,,,,,,,
T0084.003,Deceptively Labeled or Translated,,An influence operation may take authentic content from other sources and add deceptive labels or deceptively translate the content into other langauges. ,Deceptively Labeled or Translated - ,,TA06,,,,,,,,,,,,,
T0084.004,Appropriate Content,,An influence operation may take content from other sources with proper attribution. This content may be either misinformation content shared by others without malicious intent but now leveraged by the campaign as disinformation or disinformation content from other sources. Examples include the appropriation of content from one inauthentic news site to another inauthentic news site or network in ways that align with the originators licensing or terms of service.,Appropriate Content - ,,TA06,,,,,,,,,,,,,
T0085,Develop Text-based Content,,"Creating and editing false or misleading text-based artifacts, often aligned with one or more specific narratives, for use in a disinformation campaign.",T0085 - Develop Text-based Content,,TA06,,,,,,,,,,,,,
T0085.001,Develop AI-Generated Text,,"AI-generated texts refers to synthetic text composed by computers using text-generating AI  technology. Autonomous generation refers to content created by a bot without human  input, also known as bot-created content generation. Autonomous generation represents  the next step in automation after language generation and may lead to automated  journalism. An influence operation may use read fakes or autonomous generation to  quickly develop and distribute content to the target audience.",Develop AI-Generated Text - ,,TA06,,,,,,,,,,,,,
T0085.002,Develop False or Altered Documents,,Develop False or Altered Documents,Develop False or Altered Documents - ,,TA06,,,,,,,,,,,,,
T0085.003,Develop Inauthentic News Articles,,An influence operation may develop false or misleading news articles aligned to their campaign goals or narratives. ,Develop Inauthentic News Articles - ,,TA06,,,,,,,,,,,,,
T0086,Develop Image-based Content,,"Creating and editing false or misleading visual artifacts, often aligned with one or more specific narratives, for use in a disinformation campaign. This may include photographing staged real-life situations, repurposing existing digital images, or using image creation and editing technologies.",T0086 - Develop Image-based Content,,TA06,,,,,,,,,,,,,
T0086.001,Develop Memes,,"Memes are one of the most important single artefact types in all of computational propaganda. Memes in this framework denotes the narrow image-based definition. But that naming is no accident, as these items have most of the important properties of Dawkins' original conception as a self-replicating unit of culture. Memes pull together reference and commentary; image and narrative; emotion and message. Memes are a powerful tool and the heart of modern influence campaigns.",Develop Memes - ,,TA06,,,,,,,,,,,,,
T0086.002,Develop AI-Generated Images (Deepfakes),,"Deepfakes refer to AI-generated falsified photos, videos, or soundbites. An influence operation may use deepfakes to depict an inauthentic situation by synthetically recreating an individual’s face, body, voice, and physical gestures.",Develop AI-Generated Images (Deepfakes) - ,,TA06,,,,,,,,,,,,,
T0086.003,Deceptively Edit Images (Cheap fakes),,"Cheap fakes utilize less sophisticated measures of altering an image, video, or audio for example, slowing, speeding, or cutting footage to create a false context surrounding an image or event.",Deceptively Edit Images (Cheap fakes) - ,,TA06,,,,,,,,,,,,,
T0086.004,Aggregate Information into Evidence Collages,,Image files that aggregate positive evidence (Joan Donovan),Aggregate Information into Evidence Collages - ,,TA06,,,,,,,,,,,,,
T0087,Develop Video-based Content,,"Creating and editing false or misleading video artifacts, often aligned with one or more specific narratives, for use in a disinformation campaign. This may include staging videos of purportedly real situations, repurposing existing video artifacts, or using AI-generated video creation and editing technologies (including deepfakes).",T0087 - Develop Video-based Content,,TA06,,,,,,,,,,,,,
T0087.001,Develop AI-Generated Videos (Deepfakes),,"Deepfakes refer to AI-generated falsified photos, videos, or soundbites. An influence operation may use deepfakes to depict an inauthentic situation by synthetically recreating an individual’s face, body, voice, and physical gestures.",Develop AI-Generated Videos (Deepfakes) - ,,TA06,,,,,,,,,,,,,
T0087.002,Deceptively Edit Video (Cheap fakes),,"Cheap fakes utilize less sophisticated measures of altering an image, video, or audio for example, slowing, speeding, or cutting footage to create a false context surrounding an image or event.",Deceptively Edit Video (Cheap fakes) - ,,TA06,,,,,,,,,,,,,
T0088,Develop Audio-based Content,,"Creating and editing false or misleading audio artifacts, often aligned with one or more specific narratives, for use in a disinformation campaign. This may include creating completely new audio content, repurposing existing audio artifacts (including cheap fakes), or using AI-generated audio creation and editing technologies (including deepfakes).",T0088 - Develop Audio-based Content,,TA06,,,,,,,,,,,,,
T0088.001,Develop AI-Generated Audio (Deepfakes),,"Deepfakes refer to AI-generated falsified photos, videos, or soundbites. An influence operation may use deepfakes to depict an inauthentic situation by synthetically recreating an individual’s face, body, voice, and physical gestures.",Develop AI-Generated Audio (Deepfakes) - ,,TA06,,,,,,,,,,,,,
T0088.002,Deceptively Edit Audio (Cheap fakes),,"Cheap fakes utilize less sophisticated measures of altering an image, video, or audio for example, slowing, speeding, or cutting footage to create a false context surrounding an image or event.",Deceptively Edit Audio (Cheap fakes) - ,,TA06,,,,,,,,,,,,,
T0089,Obtain Private Documents,,"Procuring documents that are not publicly available, by whatever means -- whether legal or illegal, highly-resourced or less so. These documents can include authentic non-public documents, authentic non-public documents have been altered, or inauthentic documents intended to appear as if they are authentic non-public documents. All of these types of documents can be ""leaked"" during later stages in the operation.",T0089 - Obtain Private Documents,,TA06,,,,,,,,,,,,,
T0089.001,Obtain Authentic Documents,,"Procure authentic documents that are not publicly available, by whatever means -- whether legal or illegal, highly-resourced or less so. These documents can be ""leaked"" during later stages in the operation.",Obtain Authentic Documents - ,,TA06,,,,,,,,,,,,,
T0089.002,Create Inauthentic Documents,,"Create inauthentic documents intended to appear as if they are authentic non-public documents. These documents can be ""leaked"" during later stages in the operation.",Create Inauthentic Documents - ,,TA06,,,,,,,,,,,,,
T0089.003,Alter Authentic Documents,,"Alter authentic documents (public or non-public) to achieve campaign goals. The altered documents are intended to appear as if they are authentic can be ""leaked"" during later stages in the operation.",Alter Authentic Documents - ,,TA06,,,,,,,,,,,,,
T0090,Create Inauthentic Accounts,,"Inauthentic accounts include bot accounts, cyborg accounts, sockpuppet accounts, and anonymous accounts.",T0090 - Create Inauthentic Accounts,,TA15,,,,,,,,,,,,,
T0090.001,Create Anonymous Accounts,,Anonymous accounts or anonymous users refer to users that access network resources without  providing a username or password. An influence operation may use anonymous accounts to spread content without direct attribution to the operation. ,Create Anonymous Accounts - ,,TA15,,,,,,,,,,,,,
T0090.002,Create Cyborg Accounts,,"Cyborg accounts refer to partly manned, partly automated social media accounts. Cyborg  accounts primarily act as bots, but a human operator periodically takes control of the account to  engage with real social media users by responding to comments and posting original content.  Influence operations may use cyborg accounts to reduce the amount of direct human input  required to maintain a regular account but increase the apparent legitimacy of the cyborg account  by occasionally breaking its bot-like behavior with human interaction. ",Create Cyborg Accounts - ,,TA15,,,,,,,,,,,,,
T0090.003,Create Bot Accounts,,"Bots refer to autonomous internet users that interact with systems or other users while imitating  traditional human behavior. Bots use a variety of tools to stay active without direct human  operation, including artificial intelligence and big data analytics. For example, an individual may  program a Twitter bot to retweet a tweet every time it contains a certain keyword or hashtag. An  influence operation may use bots to increase its exposure and artificially promote its content  across the internet without dedicating additional time or human resources.  
Amplifier bots promote operation content through reposts, shares, and likes to increase the  content’s online popularity. Hacker bots are traditionally covert bots running on computer  scripts that rarely engage with users and work primarily as agents of larger cyberattacks, such as  a Distributed Denial of Service attacks. Spammer bots are programmed to post content on  social media or in comment sections, usually as a supplementary tool. Impersonator bots102 pose as real people by mimicking human behavior, complicating their detection.  ",Create Bot Accounts - ,,TA15,,,,,,,,,,,,,
T0090.004,Create Sockpuppet Accounts,,Sockpuppet accounts refer to falsified accounts that either promote the influence operation’s  own material or attack critics of the material online. Individuals who control sockpuppet  accounts also man at least one other user account.67 Sockpuppet accounts help legitimize  operation narratives by providing an appearance of external support for the material and  discrediting opponents of the operation. ,Create Sockpuppet Accounts - ,,TA15,,,,,,,,,,,,,
T0091,Recruit malign actors,,"Operators recruit bad actors paying recruiting, or exerting control over individuals includes trolls, partisans, and contractors.",T0091 - Recruit malign actors,,TA15,,,,,,,,,,,,,
T0091.001,Recruit Contractors,,Operators recruit paid contractor to support the campaign.,Recruit Contractors - ,,TA15,,,,,,,,,,,,,
T0091.002,Recruit Partisans,,Operators recruit partisans (ideologically-aligned individuals) to support the campaign.,Recruit Partisans - ,,TA15,,,,,,,,,,,,,
T0091.003,Enlist Troll Accounts,,"An influence operation may hire trolls, or human operators of fake accounts that aim to provoke  others by posting and amplifying content about controversial issues. Trolls can serve to discredit  an influence operation’s opposition or bring attention to the operation’s cause through debate.  
Classic trolls refer to regular people who troll for personal reasons, such as attention-seeking or  boredom. Classic trolls may advance operation narratives by coincidence but are not directly  affiliated with any larger operation. Conversely, hybrid trolls act on behalf of another institution, such as a state or financial organization, and post content with a specific ideological  goal. Hybrid trolls may be highly advanced and institutionalized or less organized and work for a  single individual. ",Enlist Troll Accounts - ,,TA15,,,,,,,,,,,,,
T0092,Build Network,,"Operators build their own network, creating links between accounts -- whether authentic or inauthentic -- in order amplify and promote narratives and artifacts, and encourage further growth of ther network, as well as the ongoing sharing and engagement with operational content.",T0092 - Build Network,,TA15,,,,,,,,,,,,,
T0092.001,Create Organizations,,"Influence operations may establish organizations with legitimate or falsified hierarchies, staff, and content to structure operation assets, provide a sense of legitimacy to the operation, or provide institutional backing to operation activities.",Create Organizations - ,,TA15,,,,,,,,,,,,,
T0092.002,Use Follow Trains,,"A follow train is a group of people who follow each other on a social media platform, often as a way for an individual or campaign to grow its social media following. Follow trains may be a violation of platform Terms of Service. They are also known as follow-for-follow groups.  ",Use Follow Trains - ,,TA15,,,,,,,,,,,,,
T0092.003,Create Community or Sub-group,,"When there is not an existing community or sub-group that meets a campaign's goals, an influence operation may seek to create a community or sub-group. ",Create Community or Sub-group - ,,TA15,,,,,,,,,,,,,
T0093,Acquire/Recruit Network,,"Operators acquire an existing network by paying, recruiting, or exerting control over the leaders of the existing network. ",T0093 - Acquire/Recruit Network,,TA15,,,,,,,,,,,,,
T0093.001,Fund Proxies,,"An influence operation may fund proxies, or external entities that work for the operation. An  operation may recruit/train users with existing sympathies towards the operation’s narratives  and/or goals as proxies. Funding proxies serves various purposes including: 
- Diversifying operation locations to complicate attribution  
- Reducing the workload for direct operation assets  ",Fund Proxies - ,,TA15,,,,,,,,,,,,,
T0093.002,Acquire Botnets,,A botnet is a group of bots that can function in coordination with each other. ,Acquire Botnets - ,,TA15,,,,,,,,,,,,,
T0094,Infiltrate Existing Networks,,Operators deceptively insert social assets into existing networks as group members in order to influence the members of the network and the wider information environment that the network impacts.,T0094 - Infiltrate Existing Networks,,TA15,,,,,,,,,,,,,
T0094.001,Identify susceptible targets in networks,,"When seeking to infiltrate an existing network, an influence operation may identify individuals and groups that might be susceptible to being co-opted or influenced.",Identify susceptible targets in networks - ,,TA15,,,,,,,,,,,,,
T0094.002,Utilize Butterfly Attacks,,"Butterfly attacks occur when operators pretend to be members of a certain social group, usually  a group that struggles for representation. An influence operation may mimic a group to insert  controversial statements into the discourse, encourage the spread of operation content, or promote harassment among group members. Unlike astroturfing, butterfly attacks aim to  infiltrate and discredit existing grassroots movements, organizations, and media campaigns.  ",Utilize Butterfly Attacks - ,,TA15,,,,,,,,,,,,,
T0095,Develop Owned Media Assets,,"An owned media asset refers to an agency or organization through which an influence operation  may create, develop, and host content and narratives. Owned media assets include websites,  blogs, social media pages, forums, and other platforms that facilitate the creation and  organization of content.",T0095 - Develop Owned Media Assets,,TA15,,,,,,,,,,,,,
T0096,Leverage Content Farms,,Using the services of large-scale content providers for creating and amplifying campaign artifacts at scale.,T0096 - Leverage Content Farms,,TA15,,,,,,,,,,,,,
T0096.001,Create Content Farms,,An influence operation may create an organization for creating and amplifying campaign artifacts at scale.,Create Content Farms - ,,TA15,,,,,,,,,,,,,
T0096.002,Outsource Content Creation to External Organizations,,"An influence operation may outsource content creation to external companies to avoid  attribution, increase the rate of content creation, or improve content quality, i.e., by employing an organization that can create content in the target audience’s native language. Employed  organizations may include marketing companies for tailored advertisements or external content  farms for high volumes of targeted media.  ",Outsource Content Creation to External Organizations - ,,TA15,,,,,,,,,,,,,
T0097,Create personas,,"Creating fake people, often with accounts across multiple platforms. These personas can be as simple as a name, can contain slightly more background like location, profile pictures, backstory, or can be effectively backstopped with indicators like fake identity documents. ",T0097 - Create personas,,TA16,,,,,,,,,,,,,
T0097.001,Backstop personas ,,"Create other assets/dossier/cover/fake relationships and/or connections or documents, sites, bylines, attributions, to establish/augment/inflate crediblity/believability",Backstop personas  - ,,TA16,,,,,,,,,,,,,
T0098,Establish Inauthentic News Sites,,"Modern computational propaganda makes use of a cadre of imposter news sites spreading globally. These sites, sometimes motivated by concerns other than propaganda--for instance, click-based revenue--often have some superficial markers of authenticity, such as naming and site-design. But many can be quickly exposed with reference to their owenership, reporting history and adverstising details.",T0098 - Establish Inauthentic News Sites,,TA16,,,,,,,,,,,,,
T0098.001,Create Inauthentic News Sites,,Create Inauthentic News Sites,Create Inauthentic News Sites - ,,TA16,,,,,,,,,,,,,
T0098.002,Leverage Existing Inauthentic News Sites,,Leverage Existing Inauthentic News Sites,Leverage Existing Inauthentic News Sites - ,,TA16,,,,,,,,,,,,,
T0099,Prepare Assets Impersonating Legitimate Entities,,"An influence operation may prepare assets impersonating legitimate entities to further conceal its  network identity and add a layer of legitimacy to its operation content. Users will more likely  believe and less likely fact-check news from recognizable sources rather than unknown sites.  Legitimate entities may include authentic news outlets, public figures, organizations, or state  entities.  
An influence operation may use a wide variety of cyber techniques to impersonate a legitimate  entity’s website or social media account. Typosquatting87 is the international registration of a  domain name with purposeful variations of the impersonated domain name through intentional  typos, top-level domain (TLD) manipulation, or punycode. Typosquatting facilitates the creation  of falsified websites by creating similar domain names in the URL box, leaving it to the user to  confirm that the URL is correct.  ",T0099 - Prepare Assets Impersonating Legitimate Entities,,TA16,,,,,,,,,,,,,
T0099.001,Astroturfing,,"Astroturfing occurs when an influence operation disguises itself as grassroots movement or  organization that supports operation narratives. Unlike butterfly attacks, astroturfing aims to  increase the appearance of popular support for the operation cause and does not infiltrate existing  groups to discredit their objectives.  ",Astroturfing - ,,TA16,,,,,,,,,,,,,
T0099.002,Spoof/parody account/site,,"An influence operation may prepare assets impersonating legitimate entities to further conceal its  network identity and add a layer of legitimacy to its operation content. Users will more likely  believe and less likely fact-check news from recognizable sources rather than unknown sites.  Legitimate entities may include authentic news outlets, public figures, organizations, or state  entities.  ",Spoof/parody account/site - ,,TA16,,,,,,,,,,,,,
T0100,Co-opt Trusted Sources,,"An influence operation may co-opt trusted sources by infiltrating or repurposing a source to  reach a target audience through existing, previously reliable networks. Co-opted trusted sources  may include:  
- National or local new outlets  
- Research or academic publications  
- Online blogs or websites ",T0100 - Co-opt Trusted Sources,,TA16,,,,,,,,,,,,,
T0100.001,Co-Opt Trusted Individuals,,Co-Opt Trusted Individuals,Co-Opt Trusted Individuals - ,,TA16,,,,,,,,,,,,,
T0100.002,Co-Opt Grassroots Groups,,Co-Opt Grassroots Groups,Co-Opt Grassroots Groups - ,,TA16,,,,,,,,,,,,,
T0100.003,Co-opt Influencers,,Co-opt Influencers,Co-opt Influencers - ,,TA16,,,,,,,,,,,,,
T0101,Create Localized Content,,"Localized content refers to content that appeals to a specific community of individuals, often in defined geographic areas. An operation may create localized content using local language and dialects to resonate with its target audience and blend in with other local news and social media. Localized content may help an operation increase legitimacy, avoid detection, and complicate external attribution.",T0101 - Create Localized Content,,TA05,,,,,,,,,,,,,
T0102,Leverage Echo Chambers/Filter Bubbles,,"An echo chamber refers to an internet subgroup, often along ideological lines, where  individuals only engage with “others with which they are already in agreement.” A filter bubble refers to an algorithm's placement of an individual in content that they agree with or regularly  engage with, possibly entrapping the user into a bubble of their own making. An operation may  create these isolated areas of the internet by match existing groups, or aggregating individuals  into a single target audience based on shared interests, politics, values, demographics, and other  characteristics. Echo chambers and filter bubbles help to reinforce similar biases and content to  the same target audience members. ",T0102 - Leverage Echo Chambers/Filter Bubbles,,TA05,,,,,,,,,,,,,
T0102.001,Use existing Echo Chambers/Filter Bubbles,,Use existing Echo Chambers/Filter Bubbles,Use existing Echo Chambers/Filter Bubbles - ,,TA05,,,,,,,,,,,,,
T0102.002,Create Echo Chambers/Filter Bubbles,,Create Echo Chambers/Filter Bubbles,Create Echo Chambers/Filter Bubbles - ,,TA05,,,,,,,,,,,,,
T0102.003,Exploit Data Voids,,"A data void refers to a word or phrase that results in little, manipulative, or low-quality search  engine data. Data voids are hard to detect and relatively harmless until exploited by an entity  aiming to quickly proliferate false or misleading information during a phenomenon that causes a  high number of individuals to query the term or phrase. In the Plan phase, an influence operation  may identify data voids for later exploitation in the operation.  
A 2019 report by Michael Golebiewski identifies five types of data voids. (1) “Breaking news”  data voids occur when a keyword gains popularity during a short period of time, allowing an  influence operation to publish false content before legitimate news outlets have an opportunity to  publish relevant information. (2) An influence operation may create a “strategic new terms” data  void by creating their own terms and publishing information online before promoting their  keyword to the target audience. (3) An influence operation may publish content on “outdated  terms” that have decreased in popularity, capitalizing on most search engines’ preferences for  recency. (4) “Fragmented concepts” data voids separate connections between similar ideas,  isolating segment queries to distinct search engine results. (5) An influence operation may use  “problematic queries” that previously resulted in disturbing or inappropriate content to promote  messaging until mainstream media recontextualizes the term.  ",Exploit Data Voids - ,,TA05,,,,,,,,,,,,,
T0103,Livestream,,A livestream refers to an online broadcast capability that allows for real-time communication to closed or open networks.,T0103 - Livestream,,TA07,,,,,,,,,,,,,
T0103.001,Video Livestream,,A video livestream refers to an online video broadcast capability that allows for real-time communication to closed or open networks.,Video Livestream - ,,TA07,,,,,,,,,,,,,
T0103.002,Audio Livestream,,An audio livestream refers to an online audio broadcast capability that allows for real-time communication to closed or open networks.,Audio Livestream - ,,TA07,,,,,,,,,,,,,
T0104,Social Networks,,"Social media are interactive digital channels that facilitate the creation and sharing of information, ideas, interests, and other forms of expression through virtual communities and networks.",T0104 - Social Networks,,TA07,,,,,,,,,,,,,
T0104.001,Mainstream Social Networks,,"Examples include Facebook, Twitter, LinkedIn, etc.",Mainstream Social Networks - ,,TA07,,,,,,,,,,,,,
T0104.002,Dating Apps,,Dating Apps,Dating Apps - ,,TA07,,,,,,,,,,,,,
T0104.003,Private/Closed Social Networks,,"An audio livestream refers to an online audio broadcast capability that allows for real-time communication to closed or open networks. Examples include Twitter Spaces, ",Private/Closed Social Networks - ,,TA07,,,,,,,,,,,,,
T0104.004,Interest-Based Networks,,"Examples include smaller and niche networks including Gettr, Truth Social, Parler, etc.",Interest-Based Networks - ,,TA07,,,,,,,,,,,,,
T0104.005,Use hashtags,,"Use a dedicated, existing hashtag for the campaign/incident.",Use hashtags - ,,TA07,,,,,,,,,,,,,
T0104.006,Create dedicated hashtag,,Create a campaign/incident specific hashtag.,Create dedicated hashtag - ,,TA07,,,,,,,,,,,,,
T0105,Media Sharing Networks,,"Media sharing networks refer to services whose primary function is the hosting and sharing of specific forms of media. Examples include Instagram, Snapchat, TikTok, Youtube, SoundCloud.",T0105 - Media Sharing Networks,,TA07,,,,,,,,,,,,,
T0105.001,Photo Sharing,,"Examples include Instagram, Snapchat, Flickr, etc",Photo Sharing - ,,TA07,,,,,,,,,,,,,
T0105.002,Video Sharing,,"Examples include Youtube, TikTok, ShareChat, Rumble, etc",Video Sharing - ,,TA07,,,,,,,,,,,,,
T0105.003,Audio sharing,,"Examples include podcasting apps, Soundcloud, etc.",Audio sharing - ,,TA07,,,,,,,,,,,,,
T0106,Discussion Forums,,"Platforms for finding, discussing, and sharing information and opinions. Examples include Reddit, Quora, Digg, message boards, interest-based discussion forums, etc.",T0106 - Discussion Forums,,TA07,,,,,,,,,,,,,
T0106.001,Anonymous Message Boards,,Examples include the Chans,Anonymous Message Boards - ,,TA07,,,,,,,,,,,,,
T0107,Bookmarking and Content Curation,,"Platforms for searching, sharing, and curating content and media. Examples include Pinterest, Flipboard, etc.",T0107 - Bookmarking and Content Curation,,TA07,,,,,,,,,,,,,
T0108,Blogging and Publishing Networks,,"Examples include WordPress, Blogger, Weebly, Tumblr, Medium, etc. ",T0108 - Blogging and Publishing Networks,,TA07,,,,,,,,,,,,,
T0109,Consumer Review Networks,,"Platforms for finding, reviewing, and sharing information about brands, products, services, restaurants, travel destinations, etc.  Examples include Yelp, TripAdvisor, etc.",T0109 - Consumer Review Networks,,TA07,,,,,,,,,,,,,
T0110,Formal Diplomatic Channels,,"Leveraging formal, traditional, diplomatic channels to communicate with foreign governments (written documents, meetings, summits, diplomatic visits, etc). This type of diplomacy is conducted by diplomats of one nation with diplomats and other officials of another nation or international organization.",T0110 - Formal Diplomatic Channels,,TA07,,,,,,,,,,,,,
T0111,Traditional Media,,"Examples include TV, Newspaper, Radio, etc.",T0111 - Traditional Media,,TA07,,,,,,,,,,,,,
T0111.001,TV,,TV,TV - ,,TA07,,,,,,,,,,,,,
T0111.002,Newspaper,,Newspaper,Newspaper - ,,TA07,,,,,,,,,,,,,
T0111.003,Radio,,Radio,Radio - ,,TA07,,,,,,,,,,,,,
T0112,Email,,Delivering content and narratives via email. This can include using list management or high-value individually targeted messaging.,T0112 - Email,,TA07,,,,,,,,,,,,,
T0113,Employ Commercial Analytic Firms,,"Commercial analytic firms collect data on target audience activities and evaluate the data to  detect trends, such as content receiving high click-rates. An influence operation may employ  commercial analytic firms to facilitate external collection on its target audience, complicating attribution efforts and better tailoring the content to audience preferences.  ",T0113 - Employ Commercial Analytic Firms,,TA08,,,,,,,,,,,,,
T0114,Deliver Ads,,Delivering content via any form of paid media or advertising.,T0114 - Deliver Ads,,TA09,,,,,,,,,,,,,
T0114.001,Social media,,Social Media,Social media - ,,TA09,,,,,,,,,,,,,
T0114.002,Traditional Media,,"Examples include TV, Radio, Newspaper, billboards",Traditional Media - ,,TA09,,,,,,,,,,,,,
T0115,Post Content,,Delivering content by posting via owned media (assets that the operator controls). ,T0115 - Post Content,,TA09,,,,,,,,,,,,,
T0115.001,Share Memes,,"Memes are one of the most important single artefact types in all of computational propaganda. Memes in this framework denotes the narrow image-based definition. But that naming is no accident, as these items have most of the important properties of Dawkins' original conception as a self-replicating unit of culture. Memes pull together reference and commentary; image and narrative; emotion and message. Memes are a powerful tool and the heart of modern influence campaigns.",Share Memes - ,,TA09,,,,,,,,,,,,,
T0115.002,Post Violative Content to Provoke Takedown and Backlash,,Post Violative Content to Provoke Takedown and Backlash.,Post Violative Content to Provoke Takedown and Backlash - ,,TA09,,,,,,,,,,,,,
T0115.003,One-Way Direct Posting,,"Direct posting refers to a method of posting content via a one-way messaging service, where the  recipient cannot directly respond to the poster’s messaging. An influence operation may post  directly to promote operation narratives to the target audience without allowing opportunities for  fact-checking or disagreement, creating a false sense of support for the narrative. ",One-Way Direct Posting - ,,TA09,,,,,,,,,,,,,
T0116,Comment or Reply on Content,,Delivering content by replying or commenting via owned media (assets that the operator controls). ,T0116 - Comment or Reply on Content,,TA09,,,,,,,,,,,,,
T0116.001,Post inauthentic social media comment,,"Use government-paid social media commenters, astroturfers, chat bots (programmed to reply to specific key words/hashtags) influence online conversations, product reviews, web-site comment forums.",Post inauthentic social media comment - ,,TA09,,,,,,,,,,,,,
T0117,Attract Traditional Media,,Deliver content by attracting the attention of traditional media (earned media).,T0117 - Attract Traditional Media,,TA09,,,,,,,,,,,,,
T0118,Amplify Existing Narrative,,An influence operation may amplify existing narratives that align with its narratives to support operation objectives. ,T0118 - Amplify Existing Narrative,,TA17,,,,,,,,,,,,,
T0119,Cross-Posting,,"Cross-posting refers to posting the same message to multiple internet discussions, social media platforms or accounts, or news groups at one time. An influence operation may post content  online in multiple communities and platforms to increase the chances of content exposure to the  target audience. ",T0119 - Cross-Posting,,TA17,,,,,,,,,,,,,
T0119.001,Post Across Groups,,An influence operation may post content across groups to spread narratives and content to new communities within the target audiences or to new target audiences. ,Post Across Groups - ,,TA17,,,,,,,,,,,,,
T0119.002,Post Across Platform,,"An influence operation may post content across platforms to spread narratives and content to new communities within the target audiences or to new target audiences. Posting across platforms can also remove opposition and context, helping the narrative spread with less opposition on the cross-posted platform. ",Post Across Platform - ,,TA17,,,,,,,,,,,,,
T0119.003,Post Across Disciplines,,Post Across Disciplines,Post Across Disciplines - ,,TA17,,,,,,,,,,,,,
T0120,Incentivize Sharing,,"Incentivizing content sharing refers to actions that encourage users to share content themselves,  reducing the need for the operation itself to post and promote its own content.",T0120 - Incentivize Sharing,,TA17,,,,,,,,,,,,,
T0120.001,Use Affiliate Marketing Programs,,Use Affiliate Marketing Programs,Use Affiliate Marketing Programs - ,,TA17,,,,,,,,,,,,,
T0120.002,Use Contests and Prizes,,Use Contests and Prizes,Use Contests and Prizes - ,,TA17,,,,,,,,,,,,,
T0121,Manipulate Platform Algorithm,,"Manipulating a platform algorithm refers to conducting activity on a platform in a way that  intentionally targets its underlying algorithm. After analyzing a platform’s algorithm (see: Select  Platforms), an influence operation may use a platform in a way that increases its content  exposure, avoids content removal, or otherwise benefits the operation’s strategy. For example, an  influence operation may use bots to amplify its posts so that the platform’s algorithm recognizes  engagement with operation content and further promotes the content on user timelines.  ",T0121 - Manipulate Platform Algorithm,,TA17,,,,,,,,,,,,,
T0121.001,Bypass Content Blocking,,"Bypassing content blocking refers to actions taken to circumvent network security measures that  prevent users from accessing certain servers, resources, or other online spheres. An influence  operation may bypass content blocking to proliferate its content on restricted areas of the  internet. Common strategies for bypassing content blocking include:
- Altering IP addresses to avoid IP filtering  
- Using a Virtual Private Network (VPN) to avoid IP filtering 
- Using a Content Delivery Network (CDN) to avoid IP filtering 
- Enabling encryption to bypass packet inspection blocking 
- Manipulating text to avoid filtering by keywords 
- Posting content on multiple platforms to avoid platform-specific removals - Using local facilities or modified DNS servers to avoid DNS filtering ",Bypass Content Blocking - ,,TA17,,,,,,,,,,,,,
T0122,Direct Users to Alternative Platforms,,"Direct users to alternative platforms refers to encouraging users to move from the  platform on which they initially viewed operation content and engage with content on alternate  information channels, including separate social media channels and inauthentic websites. An  operation may drive users to alternative platforms to diversify its information channels and ensure the target audience knows where to access operation content if the initial  platform suspends, flags, or otherwise removes original operation assets and content.  ",T0122 - Direct Users to Alternative Platforms,,TA17,,,,,,,,,,,,,
T0123,Control Information Environment through Offensive Cyberspace Operations,,Controlling the information environment through offensive cyberspace operations uses cyber tools and techniques to alter the trajectory of  content in the information space to either prioritize operation messaging or block opposition messaging.,T0123 - Control Information Environment through Offensive Cyberspace Operations,,TA18,,,,,,,,,,,,,
T0123.001,Delete Opposing Content,,"Deleting opposing content refers to the removal of content that conflicts with operational  narratives from selected platforms. An influence operation may delete opposing content to  censor contradictory information from the target audience, allowing operation narratives to take  priority in the information space.",Delete Opposing Content - ,,TA18,,,,,,,,,,,,,
T0123.002,Block Content,,Content blocking refers to actions taken to restrict internet access or render certain areas of the  internet inaccessible. An influence operation may restrict content based on both network and  content attributes. ,Block Content - ,,TA18,,,,,,,,,,,,,
T0123.003,Destroy Information Generation Capabilities,,"Destroying information generation capabilities refers to actions taken to limit, degrade, or  otherwise incapacitate an actor’s ability to generate conflicting information. An influence operation may destroy an actor’s information generation capabilities by physically dismantling  the information infrastructure, disconnecting resources needed for information generation, or  redirecting information generation personnel. An operation may destroy an adversary’s  information generation capabilities to limit conflicting content exposure to the target audience  and crowd the information space with its own narratives. ",Destroy Information Generation Capabilities - ,,TA18,,,,,,,,,,,,,
T0123.004,Conduct Server Redirect,,"A server redirect, also known as a URL redirect, occurs when a server automatically forwards a  user from one URL to another using server-side scripting languages. An influence operation may  conduct a server redirect to divert target audience members from one website to another without  their knowledge. The redirected website may pose as a legitimate source, host malware, or  otherwise aid operation objectives.",Conduct Server Redirect - ,,TA18,,,,,,,,,,,,,
T0124,Suppress Opposition,,Operators can suppress the opposition by exploiting platform content moderation tools and processes like reporting non-violative content to platforms for takedown and goading opposition actors into taking actions that result in platform action or target audience disapproval. ,T0124 - Suppress Opposition,,TA18,,,,,,,,,,,,,
T0124.001,Report Non-Violative Opposing Content,,"Reporting opposing content refers to notifying and providing an instance of a violation of a  platform’s guidelines and policies for conduct on the platform. In addition to simply reporting  the content, an operation may leverage copyright regulations to trick social media and web  platforms into removing opposing content by manipulating the content to appear in violation of  copyright laws. Reporting opposing content facilitates the suppression of contradictory  information and allows operation narratives to take priority in the information space. ",Report Non-Violative Opposing Content - ,,TA18,,,,,,,,,,,,,
T0124.002,Goad People into Harmful Action (Stop Hitting Yourself),,Goad people into actions that violate terms of service or will lead to having their content or accounts taken down. ,Goad People into Harmful Action (Stop Hitting Yourself) - ,,TA18,,,,,,,,,,,,,
T0124.003,Exploit Platform TOS/Content Moderation,,Exploit Platform TOS/Content Moderation,Exploit Platform TOS/Content Moderation - ,,TA18,,,,,,,,,,,,,
T0125,Platform Filtering,,Platform filtering refers to the decontextualization of information as claims cross platforms (from Joan Donovan https://www.hks.harvard.edu/publications/disinformation-design-use-evidence-collages-and-platform-filtering-media-manipulation),T0125 - Platform Filtering,,TA18,,,,,,,,,,,,,
T0126,Encourage Attendance at Events,,Operation encourages attendance at existing real world event.,T0126 - Encourage Attendance at Events,,TA10,,,,,,,,,,,,,
T0126.001,Call to action to attend ,,Call to action to attend an event,Call to action to attend  - ,,TA10,,,,,,,,,,,,,
T0126.002,Facilitate logistics or support for attendance,,"Facilitate logistics or support for travel, food, housing, etc.",Facilitate logistics or support for attendance - ,,TA10,,,,,,,,,,,,,
T0127,Physical Violence,,"Physical violence refers to the use of force to injure, abuse, damage, or destroy. An influence operation may conduct or encourage physical violence to discourage opponents from promoting conflicting content or draw attention to operation narratives using shock value.  ",T0127 - Physical Violence,,TA10,,,,,,,,,,,,,
T0127.001,Conduct Physical Violence,,An influence operation may directly Conduct Physical Violence to achieve campaign goals. ,Conduct Physical Violence - ,,TA10,,,,,,,,,,,,,
T0127.002,Encourage Physical Violence,,An influence operation may Encourage others to engage in Physical Violence to achieve campaign goals. ,Encourage Physical Violence - ,,TA10,,,,,,,,,,,,,
T0128,Conceal People,,Conceal the identity or provenance of a campaign account and people assets to avoid takedown and attribution.,T0128 - Conceal People,,TA11,,,,,,,,,,,,,
T0128.001,Use Pseudonyms,,"An operation may use pseudonyms, or fake names, to mask the identity of operation accounts,  publish anonymous content, or otherwise use falsified personas to conceal identity of the  operation. An operation may coordinate pseudonyms across multiple platforms, for example, by  writing an article under a pseudonym and then posting a link to the article on social media on an  account with the same falsified name.  ",Use Pseudonyms - ,,TA11,,,,,,,,,,,,,
T0128.002,Conceal Network Identity,,"Concealing network identity aims to hide the existence an influence operation’s network  completely. Unlike concealing sponsorship, concealing network identity denies the existence of  any sort of organization. ",Conceal Network Identity - ,,TA11,,,,,,,,,,,,,
T0128.003,Distance Reputable Individuals from Operation,,"Distancing reputable individuals from the operation occurs when enlisted individuals, such as  celebrities or subject matter experts, actively disengage themselves from operation activities and  messaging. Individuals may distance themselves from the operation by deleting old posts or  statements, unfollowing operation information assets, or otherwise detaching themselves from  the operation’s timeline. An influence operation may want reputable individuals to distance  themselves from the operation to reduce operation exposure, particularly if the operation aims to remove all evidence.",Distance Reputable Individuals from Operation - ,,TA11,,,,,,,,,,,,,
T0128.004,Launder Accounts,,Account laundering occurs when an influence operation acquires control of previously legitimate  online accounts from third parties through sale or exchange and often in contravention of terms  of use. Influence operations use laundered accounts to reach target audience members from an  existing information channel and complicate attribution.  ,Launder Accounts - ,,TA11,,,,,,,,,,,,,
T0128.005,Change Names of Accounts,,Changing names of accounts occurs when an operation changes the name of an existing social  media account. An operation may change the names of its accounts throughout an operation to  avoid detection or alter the names of newly acquired or repurposed accounts to fit operational  narratives.  ,Change Names of Accounts - ,,TA11,,,,,,,,,,,,,
T0129,Conceal Operational Activity,,Conceal the campaign's operational activity to avoid takedown and attribution.,T0129 - Conceal Operational Activity,,TA11,,,,,,,,,,,,,
T0129.001,Conceal Network Identity,,"Concealing network identity aims to hide the existence an influence operation’s network  completely. Unlike concealing sponsorship, concealing network identity denies the existence of  any sort of organization. ",Conceal Network Identity - ,,TA11,,,,,,,,,,,,,
T0129.002,Generate Content Unrelated to Narrative,,"An influence operation may mix its own operation content with legitimate news or external  unrelated content to disguise operational objectives, narratives, or existence. For example, an  operation may generate ""lifestyle"" or ""cuisine"" content alongside regular operation content.  ",Generate Content Unrelated to Narrative - ,,TA11,,,,,,,,,,,,,
T0129.003,Break Association with Content,,"Breaking association with content occurs when an influence operation actively separates itself  from its own content. An influence operation may break association with content by  unfollowing, unliking, or unsharing its content, removing attribution from its content, or  otherwise taking actions that distance the operation from its messaging. An influence operation may break association with its content to complicate attribution or regain credibility for a new operation.  ",Break Association with Content - ,,TA11,,,,,,,,,,,,,
T0129.004,Delete URLs,,"URL deletion occurs when an influence operation completely removes its website registration,  rendering the URL inaccessible. An influence operation may delete its URLs to complicate  attribution or remove online documentation that the operation ever occurred.",Delete URLs - ,,TA11,,,,,,,,,,,,,
T0129.005,Coordinate on encrypted/closed networks,,Coordinate on encrypted/ closed networks,Coordinate on encrypted/closed networks - ,,TA11,,,,,,,,,,,,,
T0129.006,Deny involvement,,"Without ""smoking gun"" proof (and even with proof), incident creator can or will deny involvement. This technique also leverages the attacker advantages outlined in ""Demand insurmountable proof"", specifically the asymmetric disadvantage for truth-tellers in a ""firehose of misinformation"" environment.",Deny involvement - ,,TA11,,,,,,,,,,,,,
T0129.007,Delete Accounts/Account Activity,,"Deleting accounts and account activity occurs when an influence operation removes its online  social media assets, including social media accounts, posts, likes, comments, and other online  artifacts. An influence operation may delete its accounts and account activity to complicate  attribution or remove online documentation that the operation ever occurred.  ",Delete Accounts/Account Activity - ,,TA11,,,,,,,,,,,,,
T0129.008,Redirect URLs,,"An influence operation may redirect its falsified or typosquatted URLs to legitimate websites to  increase the operation's appearance of legitimacy, complicate attribution, and avoid detection.  ",Redirect URLs - ,,TA11,,,,,,,,,,,,,
T0129.009,Remove Post Origins,,"Removing post origins refers to the elimination of evidence that indicates the initial source of  operation content, often to complicate attribution. An influence operation may remove post  origins by deleting watermarks, renaming files, or removing embedded links in its content.  ",Remove Post Origins - ,,TA11,,,,,,,,,,,,,
T0129.010,Misattribute Activity,,"Misattributed activity refers to incorrectly attributed operation activity. For example, a state sponsored influence operation may conduct operation activity in a way that mimics another state  so that external entities misattribute activity to the incorrect state. An operation may misattribute  their activities to complicate attribution, avoid detection, or frame an adversary for negative  behavior. ",Misattribute Activity - ,,TA11,,,,,,,,,,,,,
T0130,Conceal Infrastructure,,Conceal the campaign's infrastructure to avoid takedown and attribution.,T0130 - Conceal Infrastructure,,TA11,,,,,,,,,,,,,
T0130.001,Conceal Sponsorship,,"Concealing sponsorship aims to mislead or obscure the identity of the hidden sponsor behind an operation rather than entity publicly running the operation. Operations that conceal sponsorship  may maintain visible falsified groups, news outlets, non-profits, or other organizations, but seek  to mislead or obscure the identity sponsoring, funding, or otherwise supporting these entities.  
Influence operations may use a variety of techniques to mask the location of their social media  accounts to complicate attribution and conceal evidence of foreign interference. Operation  accounts may set their location to a false place, often the location of the operation’s target  audience, and post in the region’s language",Conceal Sponsorship - ,,TA11,,,,,,,,,,,,,
T0130.002,Utilize Bulletproof Hosting,,"Hosting refers to services through which storage and computing resources are provided to an  individual or organization for the accommodation and maintenance of one or more websites and  related services. Services may include web hosting, file sharing, and email distribution.  Bulletproof hosting refers to services provided by an entity, such as a domain hosting or web  hosting firm, that allows its customer considerable leniency in use of the service. An influence  operation may utilize bulletproof hosting to maintain continuity of service for suspicious, illegal,  or disruptive operation activities that stricter hosting services would limit, report, or suspend. ",Utilize Bulletproof Hosting - ,,TA11,,,,,,,,,,,,,
T0130.003,Use Shell Organizations,,Use Shell Organizations to conceal sponsorship.,Use Shell Organizations - ,,TA11,,,,,,,,,,,,,
T0130.004,Use Cryptocurrency,,"Use Cryptocurrency to conceal sponsorship. Examples include Bitcoin, Monero, and Etherium. ",Use Cryptocurrency - ,,TA11,,,,,,,,,,,,,
T0130.005,Obfuscate Payment,,Obfuscate Payment,Obfuscate Payment - ,,TA11,,,,,,,,,,,,,
T0131,Exploit TOS/Content Moderation,,Exploiting weaknesses in platforms' terms of service and content moderation policies to avoid takedowns and platform actions.,T0131 - Exploit TOS/Content Moderation,,TA11,,,,,,,,,,,,,
T0131.001,Legacy web content,,"Make incident content visible for a long time, e.g. by exploiting platform terms of service, or placing it where it's hard to remove or unlikely to be removed.",Legacy web content - ,,TA11,,,,,,,,,,,,,
T0131.002,Post Borderline Content,,Post Borderline Content,Post Borderline Content - ,,TA11,,,,,,,,,,,,,
T0132,Measure Performance,,A metric used to determine the accomplishment of actions. “Are the actions being executed as planned?”,T0132 - Measure Performance,,TA12,,,,,,,,,,,,,
T0132.001,People Focused,,Measure the performance individuals in achieving campaign goals,People Focused - ,,TA12,,,,,,,,,,,,,
T0132.002,Content Focused,,Measure the performance of campaign content,Content Focused - ,,TA12,,,,,,,,,,,,,
T0132.003,View Focused,,View Focused,View Focused - ,,TA12,,,,,,,,,,,,,
T0133,Measure Effectiveness,,A metric used to measure a current system state. “Are we on track to achieve the intended new system state within the planned timescale?”,T0133 - Measure Effectiveness,,TA12,,,,,,,,,,,,,
T0133.001,Behavior changes,,Monitor and evaluate behaviour changes from misinformation incidents. ,Behavior changes - ,,TA12,,,,,,,,,,,,,
T0133.002,Content,,Measure current system state with respect to the effectiveness of campaign content. ,Content - ,,TA12,,,,,,,,,,,,,
T0133.003,Awareness,,Measure current system state with respect to the effectiveness of influencing awareness. ,Awareness - ,,TA12,,,,,,,,,,,,,
T0133.004,Knowledge,,Measure current system state with respect to the effectiveness of influencing knowledge. ,Knowledge - ,,TA12,,,,,,,,,,,,,
T0133.005,Action/attitude,,Measure current system state with respect to the effectiveness of influencing action/attitude. ,Action/attitude - ,,TA12,,,,,,,,,,,,,
T0134,Measure Effectiveness Indicators (or KPIs),,"Ensuring that Key Performance Indicators are identified and tracked, so that the performance and effectiveness of campaigns, and elements of campaigns, can be measured, during and after their execution.",T0134 - Measure Effectiveness Indicators (or KPIs),,TA12,,,,,,,,,,,,,
T0134.001,Message reach,,Monitor and evaluate message reach in misinformation incidents. ,Message reach - ,,TA12,,,,,,,,,,,,,
T0134.002,Social media engagement,,Monitor and evaluate social media engagement in misinformation incidents.,Social media engagement - ,,TA12,,,,,,,,,,,,,
FW01,DISARM Red,,"incident creation framework. All the things that an incident creator will need to do to create, run, and assess the effectiveness of a disinformation incident.",FW01 - DISARM Red,,,,,,,,,,,,,,,
FW02,DISARM Blue,,"incident counters framework. All the things that a response team, people outside the team, and organisations outside the team, will need to do to mitigate the effects of an incident, slow down an incident, stop an incident etc.",FW02 - DISARM Blue,,,,,,,,,,,,,,,
FW03,DISARM Green,,"counter counters framework. All the things that an incident creation team might do to reduce the effectiveness of mitigations, counters, and responders to an incident. This framework doesn't officially exist yet: this id is for future work. ",FW03 - DISARM Green,,,,,,,,,,,,,,,
TK0001,Goal setting,,Set the goals for this incident. ,TK0001 - Goal setting,,TA01,FW01,,,,,,,,,,,,
TK0002,Population research / audience analysis (centre of gravity),,"Research intended audience.  Includes audience segmentation, hot-button issues etc. ",TK0002 - Population research / audience analysis (centre of gravity),,TA01,FW01,,,,,,,,,,,,
TK0003,Campaign design (objective design),,Design the campaign(s) needed to meet the incident goals,TK0003 - Campaign design (objective design),,TA01,FW01,,,,,,,,,,,,
TK0031,OPSEC for TA01,,OPSEC for TA01,TK0031 - OPSEC for TA01,,TA01,FW02,,,,,,,,,,,,
TK0004,Identify target subgroups,,Identify groups that can best be used to meet incident goals,TK0004 - Identify target subgroups,,TA02,FW01,,,,,,,,,,,,
TK0005,Analyse subgroups,,Analyse subgroups,TK0005 - Analyse subgroups,,TA02,FW01,,,,,,,,,,,,
TK0006,create master narratives,,create master narratives,TK0006 - create master narratives,,TA02,FW01,,,,,,,,,,,,
TK0007,Decide on techniques (4Ds etc),,Decide on techniques (4Ds etc),TK0007 - Decide on techniques (4Ds etc),,TA02,FW01,,,,,,,,,,,,
TK0008,Create subnarratives,,Create subnarratives,TK0008 - Create subnarratives,,TA02,FW01,,,,,,,,,,,,
TK0009,4chan/8chan coordinating content,,4chan/8chan coordinating content,TK0009 - 4chan/8chan coordinating content,,TA02,FW01,,,,,,,,,,,,
TK0032,OPSEC for TA02,,OPSEC for TA02,TK0032 - OPSEC for TA02,,TA02,FW02,,,,,,,,,,,,
TK0010,Create personas,,Create personas,TK0010 - Create personas,,TA15,FW01,,,,,,,,,,,,
TK0011,Recruit contractors,,Recruit contractors,TK0011 - Recruit contractors,,TA15,FW01,,,,,,,,,,,,
TK0012,Recruit partisans,,Recruit partisans,TK0012 - Recruit partisans,,TA15,FW01,,,,,,,,,,,,
TK0013,find influencers,,find influencers,TK0013 - find influencers,,TA15,FW01,,,,,,,,,,,,
TK0033,OPSEC for TA15,,OPSEC for TA15,TK0033 - OPSEC for TA15,,TA15,FW02,,,,,,,,,,,,
TK0014,Network building,,Network building,TK0014 - Network building,,TA15,FW01,,,,,,,,,,,,
TK0015,Network infiltration,,Network infiltration,TK0015 - Network infiltration,,TA15,FW01,,,,,,,,,,,,
TK0016,identify targets - susceptible audience members in networks,,identify targets - susceptible audience members in networks,TK0016 - identify targets - susceptible audience members in networks,,TA15,FW01,,,,,,,,,,,,
TK0034,OPSEC for TA15,,OPSEC for TA15,TK0034 - OPSEC for TA15,,TA15,FW02,,,,,,,,,,,,
TK0035,OPSEC for TA05,,OPSEC for TA05,TK0035 - OPSEC for TA05,,TA05,FW02,,,,,,,,,,,,
TK0017,content creation,,content creation,TK0017 - content creation,,TA06,FW01,,,,,,,,,,,,
TK0018,content appropriation,,content appropriation,TK0018 - content appropriation,,TA06,FW01,,,,,,,,,,,,
TK0036,OPSEC for TA06,,OPSEC for TA06,TK0036 - OPSEC for TA06,,TA06,FW02,,,,,,,,,,,,
TK0037,OPSEC for TA07,,OPSEC for TA07,TK0037 - OPSEC for TA07,,TA07,FW02,,,,,,,,,,,,
TK0019,anchor trust / credibility,,anchor trust / credibility,TK0019 - anchor trust / credibility,,TA08,FW01,,,,,,,,,,,,
TK0020,insert themes,,insert themes,TK0020 - insert themes,,TA08,FW01,,,,,,,,,,,,
TK0038,OPSEC for TA08,,OPSEC for TA08,TK0038 - OPSEC for TA08,,TA08,FW02,,,,,,,,,,,,
TK0021,"deamplification (suppression, censoring)",,"deamplification (suppression, censoring)","TK0021 - deamplification (suppression, censoring)",,TA09,FW01,,,,,,,,,,,,
TK0022,amplification,,amplification,TK0022 - amplification,,TA09,FW01,,,,,,,,,,,,
TK0039,OPSEC for TA09,,OPSEC for TA09,TK0039 - OPSEC for TA09,,TA09,FW02,,,,,,,,,,,,
TK0040,OPSEC for TA10,,OPSEC for TA10,TK0040 - OPSEC for TA10,,TA10,FW02,,,,,,,,,,,,
TK0023,retention,,retention,TK0023 - retention,,TA11,FW01,,,,,,,,,,,,
TK0024,customer relationship,,customer relationship,TK0024 - customer relationship,,TA11,FW01,,,,,,,,,,,,
TK0025,advocacy/ zealotry,,advocacy/ zealotry,TK0025 - advocacy/ zealotry,,TA11,FW01,,,,,,,,,,,,
TK0026,conversion,,conversion,TK0026 - conversion,,TA11,FW01,,,,,,,,,,,,
TK0027,keep recruiting/prospecting,,keep recruiting/prospecting,TK0027 - keep recruiting/prospecting,,TA11,FW01,,,,,,,,,,,,
TK0041,OPSEC for TA11,,OPSEC for TA11,TK0041 - OPSEC for TA11,,TA11,FW02,,,,,,,,,,,,
TK0028,evaluation,,evaluation,TK0028 - evaluation,,TA12,FW01,,,,,,,,,,,,
TK0029,post-mortem,,post-mortem,TK0029 - post-mortem,,TA12,FW01,,,,,,,,,,,,
TK0030,after-action analysis,,after-action analysis,TK0030 - after-action analysis,,TA12,FW01,,,,,,,,,,,,
TK0042,OPSEC for TA12,,OPSEC for TA12,TK0042 - OPSEC for TA12,,TA12,FW02,,,,,,,,,,,,
F00001,Analyse aborted / failed campaigns,,Examine failed campaigns. How did they fail? Can we create useful activities that increase these failures? ,F00001 - Analyse aborted / failed campaigns,,,,,,,,TA01 Strategic Planning,D01,All,,,,,
F00002,Analyse viral fizzle,,We have no idea what this means.  Is it something to do with the way a viral story spreads? ,F00002 - Analyse viral fizzle,,,,,,,,TA01 Strategic Planning,D01,"T0049 - Flooding
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0059 - Play the long game
T0060 - Continue to amplify",,,,,
F00003,Exploit counter-intelligence vs bad actors,,,F00003 - Exploit counter-intelligence vs bad actors,,,,,,,,TA01 Strategic Planning,D01,"TA06 - Develop Content
TA08 - Pump Priming
TA09 - Exposure

T0019 - Generate information pollution
T0021 - Memes",,,,,
F00004,"Recruit like-minded converts ""people who used to be in-group"" ",,,"F00004 - Recruit like-minded converts ""people who used to be in-group"" ",,,,,,,,TA01 Strategic Planning,D01,"T0057 - Organise remote rallies and events
T0061 - Sell merchandising (ie. source of identification)

T0010 - Cultivate ignorant agents
T0039 - Bait legitimate influencers",,,,,
F00005,SWOT Analysis of Cognition in Various Groups,,"Strengths, Weaknesses, Opportunities, Threats analysis of groups and audience segments. ",F00005 - SWOT Analysis of Cognition in Various Groups,,,,,,,,TA01 Strategic Planning,D01,All,,,,,
F00006,SWOT analysis of tech platforms,,,F00006 - SWOT analysis of tech platforms,,,,,,,,TA01 Strategic Planning,D01,"TA05 - Microtargeting
TA07 - Channel Selection
TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical
TA11 - Persistence

T0007 - Create fake Social Media Profiles / Pages / Groups
T0014 - Create funding campaigns
T0010 - Cultivate ignorant agents
T0019 - Generate information pollution
T0021 - Memes",,,,,
F00007,Monitor account level activity in social networks,,,F00007 - Monitor account level activity in social networks,,,,,,,,TA02 Objective Planning,D01,All,,,,,
F00008,Detect abnormal amplification,,,F00008 - Detect abnormal amplification,,,,,,,,TA15 Establish Social Assets,D01,"T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0060 - Continue to amplify",,,,,
F00009,Detect abnormal events,,,F00009 - Detect abnormal events,,,,,,,,TA15 Establish Social Assets,D01,T0007 - Create fake Social Media Profiles / Pages / Groups,,,,,
F00010,Detect abnormal groups,,,F00010 - Detect abnormal groups,,,,,,,,TA15 Establish Social Assets,D01,T0007 - Create fake Social Media Profiles / Pages / Groups,,,,,
F00011,Detect abnormal pages,,,F00011 - Detect abnormal pages,,,,,,,,TA15 Establish Social Assets,D01,T0007 - Create fake Social Media Profiles / Pages / Groups,,,,,
F00012,"Detect abnormal profiles, e.g. prolific pages/ groups/ people",,,"F00012 - Detect abnormal profiles, e.g. prolific pages/ groups/ people",,,,,,,,TA15 Establish Social Assets,D01,T0007 - Create fake Social Media Profiles / Pages / Groups,,,,,
F00013,Identify fake news sites,,,F00013 - Identify fake news sites,,,,,,,,TA15 Establish Social Assets,D01,T0008,,,,,
F00014,Trace connections,,for e.g. fake news sites,F00014 - Trace connections,,,,,,,,TA15 Establish Social Assets,D01,T0008,,,,,
F00015,Detect anomalies in membership growth patterns,,I include Fake Experts as they may use funding campaigns such as Patreon to fund their operations and so these should be watched.,F00015 - Detect anomalies in membership growth patterns,,,,,,,,TA15 Establish Social Assets,D01,"TA07 - Channel Selection

T0007 - Create fake Social Media Profiles / Pages / Groups
T0009 - Create fake experts
T0015 - Create hashtag
T0045 - Use fake experts
T0057 - Organise remote rallies and events",,,,,
F00016,Identify fence-sitters,,"Note: In each case, depending on the platform there may be a way to identify a fence-sitter. For example, online polls may have a neutral option or a ""somewhat this-or-that"" option, and may reveal who voted for that to all visitors. This information could be of use to data analysts.

In TA08-11, the engagement level of victims could be identified to detect and respond to increasing engagement.",F00016 - Identify fence-sitters,,,,,,,,TA15 Establish Social Assets,D01,"TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical
TA11 - Persistence

T0010 - Cultivate ignorant agents
T0017 - Promote online funding
T0018 - Paid targeted ads
T0029 - Manipulate online polls
T0039 - Bait legitimate influencers
T0048 - Cow online opinion leaders",,,,,
F00017,Measure emotional valence,,,F00017 - Measure emotional valence,,,,,,,,TA15 Establish Social Assets,D01,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0039 - Bait legitimate influencers
T0053 - Twitter trolls amplify and manipulate",,,,,
F00018,Follow the money,,track funding sources,F00018 - Follow the money,,,,,,,,TA15 Establish Social Assets,D01,T0009,,,,,
F00019,Activity resurgence detection (alarm when dormant accounts become activated),,,F00019 - Activity resurgence detection (alarm when dormant accounts become activated),,,,,,,,TA15 Establish Social Assets,D01,T0011 - Hijack accounts,,,,,
F00020,Detect anomalous activity,,,F00020 - Detect anomalous activity,,,,,"A015 - general public,A001 - data scientist,A031 - social media platform administrator",R004 - platform algorithms,,TA15 Establish Social Assets,D01,T0011 - Hijack accounts,,,,,
F00021,AI/ML automated early detection of campaign planning,,,F00021 - AI/ML automated early detection of campaign planning,,,,,,,,TA15 Establish Social Assets,D01,"TA15 - Establish Social Assets
TA15 - Develop Networks
TA05 - Microtargeting
TA06 - Develop Content
TA07 - Channel Selection
TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical
TA11 - Persistence",,,,,
F00022,Digital authority - regulating body (united states),,,F00022 - Digital authority - regulating body (united states),,,,,,,,TA15 Establish Social Assets,D01,,,,,,
F00023,Periodic verification (counter to hijack legitimate account),,,F00023 - Periodic verification (counter to hijack legitimate account),,,,,,,,TA15 Establish Social Assets,D01,T0011 - Hijack accounts,,,,,
F00024,Teach civics to kids/ adults/ seniors,,,F00024 - Teach civics to kids/ adults/ seniors,,,,,,,,TA15 Establish Social Assets,D01,,,,,,
F00025,Boots-on-the-ground early narrative detection,,,F00025 - Boots-on-the-ground early narrative detection,,,,,,,,TA05 Microtargeting,D01,"TA01 - Strategic Planning
TA02 - Objective Planning",,,,,
F00026,Language anomoly detection,,,F00026 - Language anomoly detection,,,,,,,,TA05 Microtargeting,D01,,,,,,
F00027,Unlikely correlation of sentiment on same topics,,,F00027 - Unlikely correlation of sentiment on same topics,,,,,,,,TA05 Microtargeting,D01,,,,,,
F00028,Associate a public key signature with government documents,,,F00028 - Associate a public key signature with government documents,,,,,,,,TA06 Develop Content,D01,T0025 - Leak altered documents,,,,,
F00029,"Detect proto narratives, i.e. RT, Sputnik",,,"F00029 - Detect proto narratives, i.e. RT, Sputnik",,,,,,,,TA06 Develop Content,D01,"TA01 - Strategic Planning

T0006 - Create Master Narratives
T0019 - Generate information pollution
T0050 - Cheerleading domestic social media ops
T0056 - Dedicated channels disseminate information pollution",,,,,
F00030,Early detection and warning - reporting of suspect content,,,F00030 - Early detection and warning - reporting of suspect content,,,,,,,,TA06 Develop Content,D01,"TA15 - Establish Social Assets
TA15 - Develop Networks
TA05 - Microtargeting
TA06 - Develop Content
TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical",,,,,
F00031,Educate on how to identify information pollution,,Strategic planning included as innoculating population has strategic value.,F00031 - Educate on how to identify information pollution,,,,,,,,TA06 Develop Content,D01,"TA01 - Strategic Planning

T0019 - Generate information pollution
T0056 - Dedicated channels disseminate information pollution",,,,,
F00032,Educate on how to identify to pollution,,DUPLICATE - DELETE ,F00032 - Educate on how to identify to pollution,,,,,,,,TA06 Develop Content,D01,DUPLICATE - DELETE ,,,,,
F00033,Fake websites: add transparency on business model,,,F00033 - Fake websites: add transparency on business model,,,,,,,,TA06 Develop Content,D01,T0013 - Create fake websites,,,,,
F00034,Flag the information spaces so people know about active flooding effort,,,F00034 - Flag the information spaces so people know about active flooding effort,,,,,,,,TA06 Develop Content,D01,T0049 - Flooding,,,,,
F00035,Identify repeated narrative DNA,,,F00035 - Identify repeated narrative DNA,,,,,,,,TA06 Develop Content,D01,"TA01 - Strategic Planning

T0006 - Create Master Narratives
T0019 - Generate information pollution
T0050 - Cheerleading domestic social media ops
T0056 - Dedicated channels disseminate information pollution",,,,,
F00036,Looking for AB testing in unregulated channels,,,F00036 - Looking for AB testing in unregulated channels,,,,,,,,TA06 Develop Content,D01,T0020 - Trial content,,,,,
F00037,News content provenance certification. ,,"Original Comment: Shortcomings: intentional falsehood. Doesn't solve accuracy. Can't be mandatory. 

Technique should be in terms of ""strategic innoculation"", raising the standards of what people expect in terms of evidence when consuming news.",F00037 - News content provenance certification. ,,,,,,,,TA06 Develop Content,D01,TA01 - Strategic Planning* (non-existent technique),,,,,
F00038,Social capital as attack vector,,"Unsure I understood the original intention or what it applied to. Therefore the techniques listed (10, 39, 43, 57, 61) are under my interpretation - which is that we want to track ignorant agents who fall into the enemy's trap and show a cost to financing/reposting/helping the adversary via public shaming or other means.",F00038 - Social capital as attack vector,,,,,,,,TA06 Develop Content,D01,"T0010 - Cultivate ignorant agents
T0039 - Bait legitimate influencers
T0043 - Use SMS/ WhatsApp/ Chat apps
T0057 - Organise remote rallies and events
T0061 - Sell merchandising",,,,,
F00039,standards to track image/ video deep fakes - industry,,,F00039 - standards to track image/ video deep fakes - industry,,,,,,,,TA06 Develop Content,D01,T0024 - Create fake videos and images,,,,,
F00040,Unalterable metadata signature on origins of image and provenance,,,F00040 - Unalterable metadata signature on origins of image and provenance,,,,,,,,TA06 Develop Content,D01,T0024 - Create fake videos and images,,,,,
F00041,Bias detection,,Not technically left of boom,F00041 - Bias detection,,,,,,,,TA07 Channel Selection,D01,T00029,,,,,
F00042,Categorize polls by intent,,"Use T00029, but against the creators",F00042 - Categorize polls by intent,,,,,,,,TA07 Channel Selection,D01,T00029,,,,,
F00043,Monitor for creation of fake known personas,,Platform companies and some information security companies (e.g. ZeroFox) do this. ,F00043 - Monitor for creation of fake known personas,,,,,"A031 - social media platform administrator,A015 - general public",,,TA07 Channel Selection,D01,T00030,,,,,
F00044,Forensic analysis,,Can be used in all phases for all techniques.,F00044 - Forensic analysis,,,,,,,,TA08 Pump Priming,D01,All,,,,,
F00045,Forensic linguistic analysis,,Can be used in all phases for all techniques.,F00045 - Forensic linguistic analysis,,,,,,,,TA08 Pump Priming,D01,All,,,,,
F00046,Pump priming analytics,,,F00046 - Pump priming analytics,,,,,,,,TA08 Pump Priming,D01,TA08 - Pump Priming,,,,,
F00047,trace involved parties,,,F00047 - trace involved parties,,,,,,,,TA08 Pump Priming,D01,,,,,,
F00048,Trace known operations and connection,,,F00048 - Trace known operations and connection,,,,,,,,TA08 Pump Priming,D01,,,,,,
F00049,trace money,,,F00049 - trace money,,,,,,,,TA08 Pump Priming,D01,,,,,,
F00050,Web cache analytics,,,F00050 - Web cache analytics,,,,,,,,TA08 Pump Priming,D01,,,,,,
F00051,Challenge expertise,,,F00051 - Challenge expertise,,,,,,,,TA09 Exposure,D01,"T0009 - Create fake experts
T0045 - Use fake experts",,,,,
F00052,Discover sponsors,,"Discovering the sponsors behind a campaign, narrative, bot, a set of accounts, or a social media comment, or anything else is useful.",F00052 - Discover sponsors,,,,,,,,TA09 Exposure,D01,All,,,,,
F00053,Government rumour control office (what can we learn?),,,F00053 - Government rumour control office (what can we learn?),,,,,,,,TA09 Exposure,D01,"T0049
T0050
T0052
T0053
T0054
T0055
T0056",,,,,
F00054,Restrict people who can @ you on social networks,,,F00054 - Restrict people who can @ you on social networks,,,,,,,,TA09 Exposure,D01,,,,,,
F00055,Verify credentials,,,F00055 - Verify credentials,,,,,,,,TA09 Exposure,D01,,,,,,
F00056,Verify organisation legitimacy,,,F00056 - Verify organisation legitimacy,,,,,,,,TA09 Exposure,D01,,,,,,
F00057,Verify personal credentials of experts,,,F00057 - Verify personal credentials of experts,,,,,,,,TA09 Exposure,D01,,,,,,
F00058,Deplatform (cancel culture),,"*Deplatform People: This technique needs to be a bit more specific to distinguish it from ""account removal"" or DDOS and other techniques that get more specific when applied to content.

For example, other ways of deplatforming people include attacking their sources of funds, their allies, their followers, etc.",F00058 - Deplatform (cancel culture),,,,,,,,TA10 Go Physical,D01,"TA07 - Channel Selection
TA09 - Exposure
TA10 - Go Physical

T0007 - Create fake Social Media Profiles / Pages / Groups
T0009 - Create fake experts
T0011 - Hijack legitimate account
T0014 - Create funding campaigns
T0017 - Promote online funding
T0018 - Paid targeted ads
T0045 - Use fake experts",,,,,
F00059,Identify susceptible demographics,,"All techniques provide or are susceptible to being countered by, or leveraged for, knowledge about user demographics.",F00059 - Identify susceptible demographics,,,,,,,,TA10 Go Physical,D01,All,,,,,
F00060,Identify susceptible influencers,,"I assume this was a transcript error. Otherwise, ""Identify Susceptible Influences"" as in the various methods of influences that may work against a victim could also be a technique. Nope, wasn't a transcript error: original note says influencers, as in find people of influence that might be targetted. ",F00060 - Identify susceptible influencers,,,,,,,,TA10 Go Physical,D01,T0039 - Bait legitimate influencers,,,,,
F00061,Microtargeting,,,F00061 - Microtargeting,,,,,,,,TA10 Go Physical,D01,All,,,,,
F00062,Detect when Dormant account turns active,,,F00062 - Detect when Dormant account turns active,,,,,,,,TA11 Persistence,D01,"TA09 - Exposure

T0007 - Create fake Social Media Profiles / Pages / Groups
T0011 - Hijack legitimate account",,,,,
F00063,Linguistic change analysis,,,F00063 - Linguistic change analysis,,,,,,,,TA11 Persistence,D01,,,,,,
F00064,Monitor reports of account takeover,,,F00064 - Monitor reports of account takeover,,,,,,,,TA11 Persistence,D01,T0011 - Hijack legitimate account,,,,,
F00065,Sentiment change analysis,,,F00065 - Sentiment change analysis,,,,,,,,TA11 Persistence,D01,,,,,,
F00066,"Use language errors, time to respond to account bans and lawsuits, to indicate capabilities",,,"F00066 - Use language errors, time to respond to account bans and lawsuits, to indicate capabilities",,,,,,,,TA11 Persistence,D01,,,,,,
F00067,Data forensics,,,F00067 - Data forensics,,,,,A001 - data scientist,,"I00029,I00045",,D01,,,,,,
F00068,Resonance analysis,,"a developing methodology for identifying statistical differences in how social groups use language and quantifying how common those statistical differences are within a larger population. In essence, it hypothesizes how much affinity might exist for a specific group within a general population, based on the language its members employ",F00068 - Resonance analysis,,,,,,,,,D01,,,,,,
F00069,Track Russian media and develop analytic methods.,,"To effectively counter Russian propaganda, it will be critical to track Russian influence efforts. The information requirements are varied and include the following: • Identify fake-news stories and their sources. • Understand narrative themes and content that pervade various Russian media sources. • Understand the broader Russian strategy that underlies tactical propaganda messaging.",F00069 - Track Russian media and develop analytic methods.,,,,,,,,,D01,,,,,,
F00070,Full spectrum analytics,,,F00070 - Full spectrum analytics,,,,,A001 - data scientist,,,ALL,D01,,,,,,
F00071,Network analysis Identify/cultivate/support influencers,,"Local influencers detected via Twitter networks are likely local influencers in other online and off-line channels as well. In addition, the content and themes gleaned from Russia and Russia-supporting populations, as well as anti-Russia activists, likely swirl in other online and off-line mediums as well.",F00071 - Network analysis Identify/cultivate/support influencers,,,,,A001 - data scientist,,,,D01,,,,,,
F00072,network analysis to identify central users in the pro-Russia activist community.,,It is possible that some of these are bots or trolls and could be flagged for suspension for violating Twitter’s terms of service.,F00072 - network analysis to identify central users in the pro-Russia activist community.,,,,,A001 - data scientist,,,,D01,,,,,,
F00073,collect intel/recon on black/covert content creators/manipulators,,"Players at the level of covert attribution, referred to as “black” in the grayscale of deniability, produce content on user-generated media, such as YouTube, but also add fear-mongering commentary to and amplify content produced by others and supply exploitable content to data dump websites. These activities are conducted by a network of trolls, bots, honeypots, and hackers. ",F00073 - collect intel/recon on black/covert content creators/manipulators,,,,,,,,,D01,,,,,,
F00074,identify relevant fence-sitter communities,,"brand ambassador programs could be used with influencers across a variety of social media channels. It could also target other prominent experts, such as academics, business leaders, and other potentially prominent people. Authorities must ultimately take care in implementing such a program given the risk that contact with U.S. or NATO authorities might damage influencer reputations. Engagements must consequently be made with care, and, if possible, government interlocutors should work through local NGOs.",F00074 - identify relevant fence-sitter communities,,,,,,,,,D01,,,,,,
F00075,leverage open-source information,,"significant amounts of quality open-source information are now available and should be leveraged to build products and analysis prior to problem prioritization in the areas of observation, attribution, and intent. Successfully distinguishing the gray zone campaign signal through the global noise requires action through the entirety of the national security community. Policy, process, and tools must all adapt and evolve to detect, discern, and act upon a new type of signal",F00075 - leverage open-source information,,,,,,,,,D01,,,,,,
F00076,Monitor/collect audience engagement data connected to “useful idiots”,,"Target audience connected to ""useful idiots rather than the specific profiles because - The active presence of such sources complicates targeting of Russian propaganda, given that it is often difficult to discriminate between authentic views and opinions on the internet and those disseminated by the Russian state.
",F00076 - Monitor/collect audience engagement data connected to “useful idiots”,,,,,,,,,D01,,,,,,
F00077,Model for bot account behavior,,"Bot account: action based, people. Unsure which DISARM techniques.",F00077 - Model for bot account behavior,,,,,,,,TA15 - Establish Social Assets,D01,,,,,,
F00078,Monitor account level activity in social networks,,All techniques benefit from careful analysis and monitoring of activities on social network.,F00078 - Monitor account level activity in social networks,,,,,,,,TA15 - Establish Social Assets,D01,All,,,,,
F00079,Network anomaly detection,,,F00079 - Network anomaly detection,,,,,A001 - data scientist,,,TA05 Microtargeting,D01,"T0029 - Manipulate online polls
T0047 - Muzzle social media as a political force
T0049 - Flooding
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0060 - Continue to amplify",,,,,
F00080,Hack the polls/ content yourself,,"Two wrongs don't make a right? But if you hack your own polls, you do learn how it could be done, and learn what to look for",F00080 - Hack the polls/ content yourself,,,,,A015 - general public,,,TA07 Channel Selection,D01,T0029 - Manipulate online polls,,,,,
F00081,Need way for end user to report operations,,,F00081 - Need way for end user to report operations,,,,,,,,TA09 Exposure,D01,"T0049
T0050
T0052
T0053
T0054
T0055
T0056",,,,,
F00082,"Control the US ""slang"" translation boards",,,"F00082 - Control the US ""slang"" translation boards",,,,,A028 - platform administrator,R005 - slang translation,,TA11 Persistence,D03,,,,,,
F00083,"Build and own meme generator, then track and watermark contents",,,"F00083 - Build and own meme generator, then track and watermark contents",,,,,,,,TA11 Persistence,D05,"T0012 - Use concealment
T0021 - Memes",,,,,
F00084,Track individual bad actors,,,F00084 - Track individual bad actors,,,,,,,,TA15 - Establish Social Assets,D01,,,,,,
F00085,detection of a weak signal through global noise,,"Gray zone threats are challenging given that warning requires detection of a weak signal through global noise and across threat vectors and regional boundaries.Three interconnected gray zone elements characterize the nature of the activity: 
Temporality: The nature of gray zone threats truly requires a “big picture view” over long timescales and across regions and functional topics.
Attribution: requiring an “almost certain” or “nearly certain analytic assessment before acting costs time and analytic effort
Intent: judgement of adversarial intent to conduct gray zone activity. Indeed, the purpose of countering gray zone threats is to deter adversaries from fulfilling their intent to act. While attribution is one piece of the puzzle, closing the space around intent often means synthesizing multiple relevant indicators and warnings, including the state’s geopolitical ambitions, military ties, trade and investment, level of corruption, and media landscape, among others.",F00085 - detection of a weak signal through global noise,,,,,,,,,,,,,,,
F00086,Outpace Competitor Intelligence Capabilities,,"Develop an intelligence-based understanding of foreign actors’ motivations, psychologies, and societal and geopolitical contexts. Leverage artificial intelligence to identify patterns and infer competitors’ intent",F00086 - Outpace Competitor Intelligence Capabilities,,,,,,,,TA02 Objective planning,D01,,,,,,
F00087,Improve Indications and Warning,,"United States has not adequately adapted its information indicators and thresholds for warning policymakers to account for gray zone tactics. Competitors have undertaken a marked shift to slow-burn, deceptive, non-military, and indirect challenges to U.S. interests. Relative to traditional security indicators and warnings, these are more numerous and harder to detect and make it difficult for analysts to infer intent.",F00087 - Improve Indications and Warning,,,,,,,,,D01,,,,,,
F00088,"Revitalize an “active measures working group,”",,"Recognize campaigns from weak signals, including rivals’ intent, capability, impact, interactive effects, and impact on U.S. interests... focus on adversarial covert action aspects of campaigning.","F00088 - Revitalize an “active measures working group,”",,,,,,,,,D01,,,,,,
F00089,"target/name/flag ""grey zone"" website content",,"""Gray zone"" is second level of content producers and circulators, composed of outlets with uncertain attribution. This category covers conspiracy websites, far-right or far-left websites, news aggregators, and data dump websites","F00089 - target/name/flag ""grey zone"" website content",,,,,,,,TA15 Establish Social Assets,D01,,,,,,
F00090,Match Punitive Tools with Third-Party Inducements,,Bring private sector and civil society into accord on U.S. interests,F00090 - Match Punitive Tools with Third-Party Inducements,,,,,,,,TA01 Strategic Planning,D01,,,,,,
F00091,Partner to develop analytic methods & tools,,"This might include working with relevant technology firms to ensure that contracted analytic support is available. Contracted support is reportedly valuable because technology to monitor social media data is continually evolving, and such firms can provide the expertise to help identify and analyze trends, and they can more effectively stay abreast of the changing systems and develop new models as they are required",F00091 - Partner to develop analytic methods & tools,,,,,"A001 data scientist,A024 developer",,,TA01 Strategic Planning,D01,,,,,,
F00092,daylight,,Warn social media companies about an ongoing campaign (e.g. antivax sites).  Anyone with datasets or data summaries can help with this,F00092 - daylight,,,,,A015 - general public,R006 - disinformation datasets,I00002,TA09 Exposure,D01,,,,,,
F00093,S4d detection and re-allocation approaches,,"S4D is a way to separate out different speakers in text, audio. ",F00093 - S4d detection and re-allocation approaches,,,,M004 - friction,,,,TA15 - Establish Social Assets,D01,T0011 - Hijack legitimate account,,,,,
F00094,Registries alert when large batches of newsy URLs get registered together,,,F00094 - Registries alert when large batches of newsy URLs get registered together,,,,M003 - daylight,A028 - platform administrator,,,TA07 Channel Selection,D01,"T0013 - Create fake websites
T0008 - Create fake or imposter news sites",,,,,
F00095,Fact checking,,"Process suspicious artifacts, narratives, and incidents",F00095 - Fact checking,,,,,,,,TA09 Exposure,D01,,,,,,
C00022,Innoculate. Positive campaign to promote feeling of safety,,Used to counter ability based and fear based attacks,C00022 - Innoculate. Positive campaign to promote feeling of safety,,,,M001 - resilience,,,,TA01 Strategic Planning,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0053 - Twitter trolls amplify and manipulate
T0044 - Seed distortions
",,narrative,,,
C00006,Charge for social media,,"Include a paid-for privacy option, e.g. pay Facebook for an option of them not collecting your personal information.  There are examples of this not working, e.g. most people don’t use proton mail etc. ",C00006 - Charge for social media,,,,M004 - friction,A033 - social media platform owner,,,TA01 Strategic Planning,D02,"T0007 - Create fake Social Media Profiles / Pages / Groups
T0015 - Create hashtag
T0018 - Paid targeted ads
T0043 - Use SMS/ WhatsApp/ Chat apps
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
",,action,,,
C00008,Create shared fact-checking database,,"Share fact-checking resources - tips, responses, countermessages, across respose groups.  ",C00008 - Create shared fact-checking database,,,,M006 - scoring,A007 - factchecker,,,TA01 Strategic Planning,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0013 - Create fake websites
T0014 - Create funding campaigns
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0056 - Dedicated channels disseminate information pollution
T0051 - Fabricate social media comment
T0044 - Seed distortions
T0045 - Use fake experts","I00049,I00050",information,,,
C00009,Educate high profile influencers on best practices,,"Find online influencers. Provide training in the mechanisms of disinformation, how to spot campaigns, and/or how to contribute to responses by countermessaging, boosting information sites etc. ",C00009 - Educate high profile influencers on best practices,,,,M001 - resilience,"A016 - influencer,A006 - educator",,,TA02 Objective Planning,D02,"T0010 - Cultivate ignorant agents
T0039 - Bait legitimate influencers
T0044 - Seed distortions
T0042 - Kernel of truth
T0048 - Cow online opinion leaders
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution",,education,,,
C00010,Enhanced privacy regulation for social media,,"Implement stronger privacy standards, to reduce the ability to microtarget community members. ",C00010 - Enhanced privacy regulation for social media,,,,M004 - friction,A020 - policy maker,,,TA01 Strategic Planning,D02,"T0005 - Center of gravity analysis
T0018 - Paid targeted ads",,regulation,,,
C00011,Media literacy. Games to identify fake news,,"Create and use games to show people the mechanics of disinformation, and how to counter them. ",C00011 - Media literacy. Games to identify fake news,,,,M001 - resilience,"A006 - educator,A026 - games designer,A024 - developer",,,TA02 Objective Planning,D02,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0013 - Create fake websites
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0056 - Dedicated channels disseminate information pollution
T0051 - Fabricate social media comment
T0044 - Seed distortions
T0045 - Use fake experts",,education,,,
C00012,Platform regulation,,"Empower existing regulators to govern social media. Also covers Destroy.  Includes: Include the role of social media in the regulatory framework for media.  The U.S. approach will need to be carefully crafted to protect First Amendment principles, create needed transparency, ensure liability, and impose costs for noncompliance. Includes Create policy that makes social media police disinformation. Includes: Use fraud legislation to clean up social media",C00012 - Platform regulation,,,,M007 - metatechnique,"A020 - policy maker,A018 - government,A033 - social media platform owner",,,TA01 Strategic Planning,D02,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0007 - Create fake Social Media Profiles / Pages / Groups
T0008 - Create fake or imposter news sites
T0009 - Create fake experts
T0013 - Create fake websites
T0014 - Create funding campaigns
T0015 - Create hashtag
T0016 - Clickbait
T0017 - Promote online funding
T0018 - Paid targeted ads
T0021 - Memes
T0022 - Conspiracy narratives
T0024 - Create fake videos and images
T0025 - Leak altered documents
T0026 - Create fake research
T0043 - Use SMS/ WhatsApp/ Chat apps
T0045 - Use fake experts
T0046 - Search Engine Optimization
T0047 - Muzzle social media as a political force
T0048 - Cow online opinion leaders
T0049 - Flooding
T0050 - Cheerleading domestic social media ops
T0051 - Fabricate social media comment
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution
T0057 - Organise remote rallies and events
T0061 - Sell merchandising",,regulation,,,
C00013,Rating framework for news,,"This is ""strategic innoculation"", raising the standards of what people expect in terms of evidence when consuming news. Example: journalistic ethics, or journalistic licensing body.  Include full transcripts, link source, add items. ",C00013 - Rating framework for news,,,,M006 - scoring,,,,TA01 Strategic Planning,D02,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0056 - Dedicated channels disseminate information pollution
T0052 - Tertiary sites amplify news",,information,,,
C00014,Real-time updates to fact-checking database,,Update fact-checking databases and resources in real time.  Especially import for time-limited events like natural disasters. ,C00014 - Real-time updates to fact-checking database,,,,M006 - scoring,A007 - factcheckers,,,TA06 Develop Content,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0013 - Create fake websites
T0014 - Create funding campaigns
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0056 - Dedicated channels disseminate information pollution
T0051 - Fabricate social media comment
T0044 - Seed distortions
T0045 - Use fake experts",,information,,,
C00016,Censorship,,Alter and/or block the publication/dissemination of information controlled by disinformation creators. Not recommended. ,C00016 - Censorship,,,,M005 - removal,A031 - social media platform administrator,,,TA01 Strategic Planning,D02,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0013 - Create fake websites
T0014 - Create funding campaign
T0015 - Create hashtag
T0016 - Clickbait 
T0017 - Promote online funding
T0018 - Paid targeted ads
T0022 - Conspiracy narratives
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0044 - Seed distortions
T0045 - Use fake experts
T0043 - Use SMS/WhatsApp/ Chat apps
T0056 - Dedicated channels disseminate information pollution
T0051 - Fabricate social media comment
T0049 - Flooding 
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0058 - Legacy web content
T0057 - Organise remote rallies and events
",,action,,,
C00017,Repair broken social connections,,"For example, use a media campaign to promote in-group to out-group in person communication / activities . Technique could be in terms of forcing a reality-check by talking to people instead of reading about bogeymen. ",C00017 - Repair broken social connections,,,,M010 - countermessaging,A021 - media organisation,,,TA01 Strategic Planning,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0023 - Distort facts",,action,,,
C00019,Reduce effect of division-enablers,,"includes Promote constructive communication by shaming division-enablers, and Promote playbooks to call out division-enablers",C00019 - Reduce effect of division-enablers,,,,M003 - daylight,,,,TA01 Strategic Planning,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0053 - Twitter trolls amplify and manipulate
T0044 - Seed distortions
T0052 - Teriary sites amplify news
T0056 - Dedicated channel disseminate information pollution",,action,,,
C00021,Encourage in-person communication,,Encourage offline communication,C00021 - Encourage in-person communication,,,,M001 - resilience,,,,TA01 Strategic Planning,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0053 - Twitter trolls amplify and manipulate
T0044 - Seed distortions
",,action,,,
C00024,Promote healthy narratives,,"Includes promoting constructive narratives i.e. not polarising (e.g. pro-life, pro-choice, pro-USA).  Includes promoting identity neutral narratives. ",C00024 - Promote healthy narratives,,,,M001 - resilience,,,,TA01 Strategic Planning,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0053 - Twitter trolls amplify and manipulate
T0044 - Seed distortions
",,narrative,,,
C00026,Shore up democracy based messages,,"Messages about e.g. peace, freedom. And make it sexy. Includes Deploy Information and Narrative-Building in Service of Statecraft: Promote a narrative of transparency, truthfulness, liberal values, and democracy. Implement a compelling narrative via effective mechanisms of communication. Continually reassess messages, mechanisms, and audiences over time. Counteract efforts to manipulate media, undermine free markets, and suppress political freedoms via public diplomacy",C00026 - Shore up democracy based messages,,,,M010 - countermessaging,,,,TA01 Strategic Planning,D04,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda",,narrative,,,
C00027,Create culture of civility,,This is passive.  Includes promoting civility as an identity that people will defend. ,C00027 - Create culture of civility,,,,M001 - resilience,,,,TA01 Strategic Planning,D07,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives
T0021 - Memes
T0023 - Distort facts
T0048 - Cow online opinion leaders
T0053 - Twitter trolls amplify and manipulate
T0044 - Seed distortions
T0039 - Bait legitimate influencers",,narrative,,,
C00029,Create fake website to issue counter narrative and counter narrative through physical merchandise,,Create websites in disinformation voids - spaces where people are looking for known disinformation. ,C00029 - Create fake website to issue counter narrative and counter narrative through physical merchandise,,,,M002 - diversion,,,,TA02 Objective Planning,D03,"T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives",,narrative,,,
C00028,Make information provenance available,,"Blockchain audit log and validation with collaborative decryption to post comments.  Use blockchain technology to require collaborative validation before posts or comments are submitted.

This could be used to adjust upvote weight via a trust factor of people and organisations you trust, or other criteria.",C00028 - Make information provenance available,,,,M011 - verification,,,,TA02 Objective Planning,D03,"TA07 - Channel Selection
TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical",,information,,,
C00030,Develop a compelling counter narrative (truth based),,,C00030 - Develop a compelling counter narrative (truth based),,,,M002 - diversion,,,,TA02 Objective Planning,D03,"T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives",,narrative,,,
C00031,"Dilute the core narrative - create multiple permutations, target / amplify",,"Create competing narratives. Included ""Facilitate State Propaganda"" as diluting the narrative could have an effect on the pro-state narrative used by volunteers, or lower their involvement.","C00031 - Dilute the core narrative - create multiple permutations, target / amplify",,,,M009 - dilution,,,,TA02 Objective Planning,D03,"T0002 - Facilitate State Propaganda
T0003 - Leverage Existing Narratives
T0006 - Create Master Narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives",,narrative,,,
C00042,Address truth contained in narratives,,"Focus on and boost truths in misinformation narratives, removing misinformation from them. ",C00042 - Address truth contained in narratives,,,,M010 - countermessaging,,,,TA15 Establish Social Assets,D04,"T0004 - Competing Narratives
T0019 - Generate information pollution
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0028 - Create competing narratives
T0042 - Kernel of Truth
T0044 - Seed distortions
T0056 - Dedicated channels disseminate information pollution
T0059 - Play the long game",,narrative,,,
C00032,Hijack content and link to truth- based info,,Link to platform,C00032 - Hijack content and link to truth- based info,,,,M002 - diversion,,,,TA06 Develop Content,D03,T0055 - Use hashtag,,information,,,
C00034,Create more friction at account creation,,Counters fake account,C00034 - Create more friction at account creation,,,,M004 - friction,,,,TA15 - Establish Social Assets,D04,"T0009 - Create fake experts
T0007 - Create fake Social Media Profiles / Pages / Groups
T0012 - Use concealment
T0030 - Backstop personas",,action,,,
C00036,Infiltrate the in-group to discredit leaders (divide),,All of these would be highly affected by infiltration or false-claims of infiltration.,C00036 - Infiltrate the in-group to discredit leaders (divide),,,,M013 - targeting,,,,TA15 - Establish Social Assets,D02,"T0005 - Center of Gravity Analysis
T0007 - Create fake Social Media Profiles / Pages / Groups
T0010 - Cultivate ignorant agents
T0012 - Use concealment
T0030 - Backstop personas
T0045 - Use fake experts
T0056 - Dedicated channels disseminate information pollution
T0057 - Organise remote rallies and events",,action,,,
C00040,third party verification for people,,counters fake experts,C00040 - third party verification for people,,,,M011 - verification,,,,TA15 - Establish Social Assets,D02,"T0007 - Create fake social media profiles
T0009 - Create fake experts
T0012 - Use concealment",,information,,,
C00067,Denigrate the recipient/ project (of online funding),,Reduce the credibility of groups behind misinformation-linked funding campaigns. ,C00067 - Denigrate the recipient/ project (of online funding),,,,M013 - targeting,,,,TA15 Establish Social Assets,D03,"T0017 - Promote online funding
T0061 - Sell merchandising",,narrative,,,
C00044,Keep people from posting to social media immediately,,"Platforms can introduce friction to slow down activities, force a small delay between posts, or replies to posts.",C00044 - Keep people from posting to social media immediately,,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA15 - Establish Social Assets,D03,"T0029 - Manipulate online polls
T0049 - Flooding
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0056 - Dedicated channel disseminate information pollution
T0051 - Fabricate social media comment
T0050 - Cheerleading domestic social media ops",,action,,,
C00046,Marginalise and discredit extremist groups,,Reduce the credibility of extremist groups posting misinformation.,C00046 - Marginalise and discredit extremist groups,,,,M013 - targeting,,,,TA15 - Establish Social Assets,D04,"T0010 - Cultivate ignorant agents
T0044 - Seed distortions
T0021 - Memes
T0022 - Conspiracy narratives
T0023 - Distort facts
T0027 - Adapt existing narratives
T0039 - Bait legitimate influencers
T0045 - Use fake experts
T0048 - Cow online opinion leaders
T0051 - Fabricate social media comment
T0052 - Teriary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0056 - Dedicated channel disseminate information pollution
T0057 - Organise remote rallies and events
T0060 - Continue to amplify
T0061 - Sell merchandising",,action,,,
C00047,Honeypot with coordinated inauthentics,,"Flood disinformation spaces with obviously fake content, to dilute core misinformation narratives in them. ",C00047 - Honeypot with coordinated inauthentics,,,,M008 - data pollution,,,,TA15 Establish Social Assets,D05,"T0063 - Social Media engagement
T0062 - Message reach",,action,,,
C00048,Name and Shame Influencers,,"Think about the different levels: individual vs state-sponsored account.  Includes “call them out” and “name and shame”.  Identify social media accounts as sources of propaganda—“calling them out”— might be helpful to prevent the spread of their message to audiences that otherwise would consider them factual.  Identify, monitor, and, if necessary, target externally-based nonattributed social media accounts.  Impact of and Dealing with Trolls - ""Chatham House has observed that trolls also sometimes function as decoys, as a way of “keeping the infantry busy” that “aims to wear down the other side” (Lough et al., 2014). Another type of troll involves “false accounts posing as authoritative information sources on social media”.",C00048 - Name and Shame Influencers,,,,M003 - daylight,,,,TA15 - Establish Social Assets,D07,"T0010 - Cultivate ignorant agents
T0045 - Use fake experts
T0048 - Cow online opinion leaders
T0051 - Fabricate social media comment
T0052 - Teriary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0056 - Dedicated channel disseminate information pollution
T0057 - Organise remote rallies and events
T0060 - Continue to amplify
T0061 - Sell merchandising",,information,,,
C00051,Counter social engineering training,,"Includes anti-elicitation training, phishing prevention education. ",C00051 - Counter social engineering training,,,,M001 - resilience,A006 - educator,,,TA15 - Establish Social Assets,D02,"T0010 - Cultivate ignorant agents
T0012 - Use concealment",,education,,,
C00052,Infiltrate platforms,,Detect and degrade,C00052 - Infiltrate platforms,,,,M013 - targeting,A004 - activist,,,TA15 Establish Social Assets,D04,"T0012 - Use concealment
T0030 - Backstop personas",,action,,,
C00053,Delete old accounts / Remove unused social media accounts,,"remove or remove access to (e.g. stop the ability to update) old social media accounts, to reduce the pool of accounts available for takeover, botnets etc. ",C00053 - Delete old accounts / Remove unused social media accounts,,,,M012 - cleaning,"A031 - social media platform administrator,A028 - platform administrator,A012 - account owner",,,TA15 Establish Social Assets,D04,"T0011 - Hijack legitimate accounts
T0030 - Backstop personas",I00004,action,,,
C00056,Encourage people to leave social media,,Encourage people to leave spcial media.  We don't expect this to work,C00056 - Encourage people to leave social media,,,,M004 - friction,,,,TA15 Establish Social Assets,D02,,,action,,,
C00058,Report crowdfunder as violator,,counters crowdfunding. Includes ‘Expose online funding as fake”. ,C00058 - Report crowdfunder as violator,,,,M005 - removal,,,,TA15 - Establish Social Assets,D02,"T0017 - Promote online funding
T0061 - Sell merchandising",,information,,,
C00059,Verification of project before posting fund requests,,third-party verification of projects posting funding campaigns before those campaigns can be posted. ,C00059 - Verification of project before posting fund requests,,,,M011 - verification,,,,TA15 Establish Social Assets,D02,T0014 - Create funding campaigns,,information,,,
C00060,Legal action against for-profit engagement factories,,"Take legal action against for-profit ""factories"" creating misinformation. ",C00060 - Legal action against for-profit engagement factories,,,,M013 - targeting,A020 - policy maker,,,TA02 Objective Planning,D03,"TA07 - Channel Selection
T0047 - Muzzle social media as a political force",,regulation,,,
C00062,Free open library sources worldwide,,"Open-source libraries could be created that aid in some way for each technique. Even for Strategic Planning, some open-source frameworks such as DISARM can be created to counter the adversarial efforts.",C00062 - Free open library sources worldwide,,,,M010 - countermessaging,,,,TA15 Establish Social Assets,D04,"TA01 - Strategic planning
TA02 - Objective planning
TA15 - Establish Social Assets
TA15 - develop networks
TA05 - microtargeting
TA06 - develop content
TA07 - channel selection
TA08 - pump priming
TA09 - exposure
TA10 - go physical
TA11 - persistence
TA12 - measure effectiveness",,information,,,
C00065,Reduce political targeting,,Includes “ban political micro targeting” and “ban political ads”,C00065 - Reduce political targeting,,,,M005 - removal,A020 - policy maker,,,TA05 Microtargeting,D03,T0018 - Paid targeted ads,,action,,,
C00066,Co-opt a hashtag and drown it out (hijack it back),,Flood a disinformation-related hashtag with other content. ,C00066 - Co-opt a hashtag and drown it out (hijack it back),,,,M009 - dilution,,,,TA05 Microtargeting,D03,"T0015 - Create hashtag
T0055 - Use hashtag",,information,,,
C00080,Create competing narrative,,"Create counternarratives, or narratives that compete in the same spaces as misinformation narratives.  Could also be degrade",C00080 - Create competing narrative,,,,M002 - diversion,,,,TA06 Develop Content,D03,"T0003 - Leverate existing narratives
T0004 - Competing narratives
T0028 - Create competing narratives
T0022 - Conspiracy narratives 
T0027 - Adapt existing narratives ",,narrative,,,
C00070,Block access to disinformation resources,,"Resources = accounts, channels etc.  Block access to platform. DDOS an attacker.

TA02*: DDOS at the critical time, to deny an adversary's time-bound objective.

T0008: A quick response to a proto-viral story will affect it's ability to spread and raise questions about their legitimacy.

Hashtag: Against the platform, by drowning the hashtag.

T0046 - Search Engine Optimization: Sub-optimal website performance affect its search engine rank, which I interpret as ""blocking access to a platform"".",C00070 - Block access to disinformation resources,,,,M005 - removal,,,,TA02 Objective Planning,D02,"T0008 - Create fake or imposter news sites
T0014 - Create funding campaigns
T0015 - Create hashtag
T0017 - Promote online funding
T0046 - Search Engine Optimization
T0052 - Tertiary sites amplify news
T0055 - Use hashtag
T0057 - Organise remote rallies and events
T0056 - Dedicated channels disseminate information pollution
T0058 - Legacy web content",,action,,,
C00071,Block source of pollution,,"Block websites, accounts, groups etc connected to misinformation and other information pollution. ",C00071 - Block source of pollution,,,,M005 - removal,,,,TA06 Develop Content,D02,"T0019 - Generate information pollution
T0056 - Dedicated channels disseminate information pollution",,action,,,
C00072,Remove non-relevant content from special interest groups - not recommended,,"Check special-interest groups (e.g. medical, knitting) for unrelated and misinformation-linked content, and remove it. ",C00072 - Remove non-relevant content from special interest groups - not recommended,,,,M005 - removal,,,,TA06 Develop Content,D02,"T0019 - Generate information pollution
T0010 - Cultivate ignorant agents
T0044 - Seed distortions
T0021 - Memes
T0022 - Conspiracy narratives
T0023 - Distort facts
T0027 - Adapt existing narratives
T0039 - Bait legitimate influencers
T0055 - Use hashtag
T0049 - Flooding
",,action,,,
C00073,Inoculate populations through media literacy training,,"Use training to build the resilience of at-risk populations. Educate on how to handle info pollution. Push out targeted education on why it's pollution.  Build cultural resistance to false content, e.g. cultural resistance to bullshit.  Influence literacy training, to inoculate against “cult” recruiting.  Media literacy training: leverage librarians / library for media literacy training. Inoculate at language.   Strategic planning included as inoculating population has strategic value.   Concepts of media literacy to a mass audience that authorities launch a public information campaign that teaches the program will take time to develop and establish impact, recommends curriculum-based training.  Covers detect, deny, and degrade. ",C00073 - Inoculate populations through media literacy training,,,,M001 - resilience,"A006 - educator,A008 - library,A017 - coordinating body,A009 - NGO,A032 - social media platform outreach,A021 - media organization,A005 - community group,A010 - religious organisation",,,TA01 Strategic Planning,D02,"T0016 - Clickbait 
T0019 - Generate information pollution
T0056 - Dedicated channels disseminate information pollution
T0010 - Cultivate ignorant agents
T0021 - Memes
T0022 - Conspiracy narratives
T0023 - Distort facts
T0026 - Create fake research
T0025 - Leak altered documents
T0027 - Adapt existing narratives
T0039 - Bait legitimate influencers
T0040 - Deny insurmountable proof
T0044 - Seed distortions
T0045 - Use fake experts
T0048 - Cow online opinion leaders
T0053 - Twitter trolls amplify and manipulate
T0056 - Dedicated channels disseminate information pollution
T0060 - Continue to amplify",,education,,,
C00074,Identify and delete or rate limit identical content,,C00000,C00074 - Identify and delete or rate limit identical content,,,,M012 - cleaning,"A031 - social media platform administrator,A028 - platform administrator",,,TA06 Develop Content,D02,"T0019 - Generate information pollution
T0021 - Memes
T0022 - Conspiracy narratives
T0026 - Create fake research
T0025 - Leak altered documents
T0043 - Use SMS
T0050 - Cheerleading domestic social media ops
T0051 - Fabricate social media comment
T0049 - Flooding
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0057 - Organise remote rallies and events
T0061 - Sell merchandising
T0060 - Continue to amplify",,action,,,
C00075,normalise language,,normalise the language around disinformation and misinformation; give people the words for artifact and effect types. ,C00075 - normalise language,,,,M010 - countermessaging,,,,TA06 Develop Content,D02,,,information,,,
C00076,Prohibit images in political discourse channels,,Make political discussion channels text-only. ,C00076 - Prohibit images in political discourse channels,,,,M005 - removal,,,,TA06 Develop Content,D02,"T0016 - Clickbait 
T0018 - Paid targeted ads
T0039 - Bait legitimate influencers
T0044 - Seed distortions
T0021 - Memes",,action,,,
C00077,"Active defence: run TA15 ""develop people” - not recommended",,Develop networks of communities and influencers around counter-misinformation. Match them to misinformation creators ,"C00077 - Active defence: run TA15 ""develop people” - not recommended",,,,M013 - targeting,,,,TA15 - Establish Social Assets,D03,,,action,,,
C00078,Change Search Algorithms for Disinformation Content,,Includes “change image search algorithms for hate groups and extremists” and “Change search algorithms for hate and extremist queries to show content sympathetic to opposite side”,C00078 - Change Search Algorithms for Disinformation Content,,,,M002 - diversion,,,,TA06 Develop Content,D03,"TA07 - Channel Selection
T0044 - Seed distortions
T0046 - Search Engine Optimization
T0056 - Dedicated channels disseminate information pollution
T0052 - Tertiary sites amplify news
T0060 - Continue to amplify",,action,,,
C00084,"Modify disinformation narratives, and rebroadcast them",,"Includes “poison pill recasting of message” and “steal their truths”.  Many techniques involve promotion which could be manipulated. For example, online fundings or rallies could be advertised, through compromised or fake channels, as being associated with ""far-up/down/left/right"" actors. ""Long Game"" narratives could be subjected in a similar way with negative connotations.  Can also replay technique T0003. ","C00084 - Modify disinformation narratives, and rebroadcast them",,,,M002 - diversion,,,,TA06 Develop Content,D03,"T0002 - Facilitate State Propaganda
T0003 - Leverate existing narratives
T0004 - Competing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0059 - Play the long game",,narrative,,,
C00081,"Highlight flooding and noise, and explain motivations",,"Discredit by pointing out the ""noise"" and informing public that ""flooding"" is a technique of disinformation campaigns; point out intended objective of ""noise""","C00081 - Highlight flooding and noise, and explain motivations",,,,M003 - daylight,,,,TA06 Develop Content,D03,"T0003 - Leverate existing narratives
T0004 - Competing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0026 - Create fake research
T0027 - Adapt existing narratives
T0044 - Seed distortions
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution",,information,,,
C00082,Ground truthing as automated response to pollution,,Also inoculation.,C00082 - Ground truthing as automated response to pollution,,,,M010 - countermessaging,,,,TA06 Develop Content,D03,"T0002 - Facilitate State Propaganda
T0003 - Leverate existing narratives
T0004 - Competing narratives
T0028 - Create competing narratives
T0006 - Create Master Narratives
T0022 - Conspiracy narratives
T0023 - Distort facts
T0025 - Leak altered documents
T0026 - Create fake research
T0027 - Adapt existing narratives
T0044 - Seed distortions
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution",,information,,,
C00087,Make more noise than the disinformation,,,C00087 - Make more noise than the disinformation,,,,M009 - dilution,,,,TA06 Develop Content,D04,"T0039 - Bait legitimate influencers
T0044 - Seed distortions
T0048 - Cow online opinion leaders
T0050 - Cheerleading domestic social media ops
T0051 - Fabricate social media comment
T0049 - Flooding 
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution",,narrative,,,
C00085,Mute content,,"Rate-limit disinformation content.  Reduces its effects, whilst not running afoul of censorship concerns.

Online archives of content (archives of websites, social media profiles, media, copies of published advertisements; or archives of comments attributed to bad actors, as well as anonymized metadata about users who interacted with them and analysis of the effect) is useful for intelligence analysis and public transparency, but will need similar muting or tagging/ shaming as associated with bad actors.",C00085 - Mute content,,,,M003 - daylight,,,,TA06 Develop Content,D03,"T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0017 - Promote online funding
T0022 - Conspiracy narratives
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0044 - Seed distortions
T0049 - Flooding 
T0051 - Fabcricate social media comment
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution
T0057 - Organise remote rallies and events
T0061 - Sell merchandising
T0060 - Continue to amplify",,action,,,
C00086,Distract from noise with addictive content,,"Example: Interject addictive links or contents into discussions of disinformation materials and measure a ""conversion rate"" of users who engage with your content and away from the social media channel's ""information bubble"" around the disinformation item. Use bots to amplify and upvote the addictive content. ",C00086 - Distract from noise with addictive content,,,,M002 - diversion,,,,TA06 Develop Content,D04,"T0044 - Seed distortions
T0050 - Cheerleading domestic social media ops
T0051 - Fabricate social media comment
T0049 - Flooding 
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
",,information,,,
C00112,"""Prove they are not an op!""",,Challenge misinformation creators to prove they're not an information operation.  ,"C00112 - ""Prove they are not an op!""",,,,M004 - friction,,,,TA08 Pump Priming,D02,"T0040 - Demand insurmontable proof
T0042 - Kernel of truth",,narrative,,,
C00090,Fake engagement system,,"Create honeypots for misinformation creators to engage with, and reduce the resources they have available for misinformation campaigns. ",C00090 - Fake engagement system,,,,M002 - diversion,,,,TA07 Channel Selection,D05,"T0020 - Trial content
T0062 - Message reach
T0063 - Social media engagement",,action,,,
C00091,Honeypot social community,,"Set honeypots, e.g. communities, in networks likely to be used for disinformation. ",C00091 - Honeypot social community,,,,M002 - diversion,,,,TA06 Develop Content,D05,"T0062 - Message reach
T0063 - Social media engagement
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0049 - Flooding",,action,,,
C00092,Establish a truth teller reputation score for influencers,,"Includes ""Establish a truth teller reputation score for influencers” and “Reputation scores for social media users”.  Influencers are individuals or accounts with many followers. ",C00092 - Establish a truth teller reputation score for influencers,,,,M006 - scoring,A001 - data scientist,R001 - datastreams,,TA02 Objective Planning,D07,"TA07 - Channel Selection
TA08 - Pump Priming
T0010 - Cultivate ignorant agents
T0023 - Distort facts
T0039 - Bait legitimate influencers
T0045 - Use fake experts
T0044 - Seed distortions
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0056 - Dedicated channels disseminate information pollution",,information,,,
C00093,Influencer code of conduct,,Establish tailored code of conduct for individuals with many followers.  Can be platform code of conduct; can also be community code.,C00093 - Influencer code of conduct,,,,M001 - resilience,,,,TA15 - Establish Social Assets,D07,"TA07 - Channel Selection
T0010 - Cultivate ignorant agents
T0017 - Promote online funding
T0039 - Bait legitimate influencers
T0047 - Muzzle social media as a political force
T0048 - Cow online opinion leaders
T0053 - Twitter trolls amplify and manipulate",,information,,,
C00094,Force full disclosure on corporate sponsor of research,,Accountability move: make sure research is published with its funding sources. ,C00094 - Force full disclosure on corporate sponsor of research,,,,M003 - daylight,,,,TA06 Develop Content,D04,T0026 - Create fake research,,information,,,
C00096,Strengthen institutions that are always truth tellers,,"Increase credibility, visibility, and reach of positive influencers in the information space. ",C00096 - Strengthen institutions that are always truth tellers,,,,M006 - scoring,,,,TA01 Strategic Planning,D07,"T0022 - Conspiracy narratives
T0027 - Adapt existing narrativies
T0026 - Create fake research
T0024 - Create fake videos and images
T0023 - Distort facts
T0025 - Leak altered documents
",,information,,,
C00097,Require use of verified identities to contribute to poll or comment,,Reduce poll flooding by online taking comments or poll entries from verified accounts. ,C00097 - Require use of verified identities to contribute to poll or comment,,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA07 Channel Selection,D02,"T0029 - Manipulate online polls
T0030 - Backstop personas
T0045 - Use fake experts
T0009 - Create fake experts
T0007 - Create fake Social Media Profiles / Pages / Groups
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate",,information,,,
C00098,"Revocation of allowlisted or ""verified"" status",,remove blue checkmarks etc from known misinformation accounts. ,"C00098 - Revocation of allowlisted or ""verified"" status",,,,M004 - friction,A031 - social media platform administrator,,,TA07 Channel Selection,D02,"T0038 - Twitter 
T0011 - Hijack legitimate account",,action,,,
C00099,Strengthen verification methods,,"Improve content veerification methods available to groups, individuals etc.  ",C00099 - Strengthen verification methods,,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA07 Channel Selection,D02,"T0030 - Backstop personas
T0045 - Use fake experts
T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups",,information,,,
C00100,Hashtag jacking,,Post large volumes of unrelated content on known misinformation hashtags ,C00100 - Hashtag jacking,,,,M002 - diversion,,,,TA08 Pump Priming,D03,T0055 - Use hashtag,,information,,,
C00101,Create friction by rate-limiting engagement,,"Create participant friction.  Includes Make repeat voting hard, and throttle number of forwards. ",C00101 - Create friction by rate-limiting engagement,,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA07 Channel Selection,D04,"T0029 - Manipulate online polls
T0049 - Flooding 
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify",,action,,,
C00103,Create a bot that engages / distract trolls,,"This is reactive, not active measure (honeypots are active).  It's a platform controlled measure.",C00103 - Create a bot that engages / distract trolls,,,,M002 - diversion,A024 - developer,,,TA07 Channel Selection,D05,"T0029 - Manipulate online polls
T0062 - Message Reach
T0063 - Social Media Engagement
T0053 - Twitter trolls amplify and manipulate",,action,,,
C00105,Buy more advertising than misinformation creators,,Shift influence and algorithms by posting more adverts into spaces than misinformation creators. ,C00105 - Buy more advertising than misinformation creators,,,,M009 - dilution,A023 - adtech provider,R003 - money,,TA07 Channel Selection,D03,"T0016 - Clickbait 
T0018 - Paid targeted ads",,information,,,
C00106,Click-bait centrist content,,Create emotive centrist content that gets more clicks,C00106 - Click-bait centrist content,,,,M002 - diversion,,,,TA06 Develop Content,D03,T0016 - Clickbait,,information,,,
C00107,Content moderation,,"includes social media content take-downs, e.g. facebook or Twitter content take-downs",C00107 - Content moderation,,,,"M006 - scoring, M005 - removal",A031 - social media platform administrator,,,TA06 Develop Content,D02,"T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0013 - Create fake websites
T0014 - Create funding campaign
T0015 - Create hashtag
T0016 - Clickbait 
T0017 - Promote online funding
T0018 - Paid targeted ads
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0055 - Use hashtag
T0057 - Organise remote rallies and events
T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0061 - Sell merchandising","I00005,I00009,I00056",action,,,
C00109,Dampen Emotional Reaction,,"Reduce emotional responses to misinformation through calming messages, etc. ",C00109 - Dampen Emotional Reaction,,,,M001 - resilience,,,,TA09 Exposure,D03,,,information,,,
C00111,Reduce polarisation by connecting and presenting sympathetic renditions of opposite views,,,C00111 - Reduce polarisation by connecting and presenting sympathetic renditions of opposite views,,,,M001 - resilience,"A021 - media organisation,A013 - content creator",,,TA01 Strategic Planning,D04,T0010 - Cultivate ignorant agents,,information,,,
C00118,Repurpose images with new text,,Add countermessage text to iamges used in misinformation incidents. ,C00118 - Repurpose images with new text,,,,M010 - countermessaging,,,,TA08 Pump Priming,D04,"T0044 - Seed distortions
T0021 - Memes 
T0024 - Create fake videos and images",,narrative,,,
C00113,Debunk and defuse a fake expert / credentials.,,"Debunk fake experts, their credentials, and potentially also their  audience quality",C00113 - Debunk and defuse a fake expert / credentials.,,,,M003 - daylight,,,,TA08 Pump Priming,D02,T0045 - Use fake experts,,information,,,
C00114,Don't engage with payloads,,Stop passing on misinformation,C00114 - Don't engage with payloads,,,,M004 - friction,A015 - general public,,,TA08 Pump Priming,D02,"T0039 - Bait legitimate inffluencers 
T0048 - Cow online opinion leaders
",,information,,,
C00115,Expose actor and intentions,,Debunk misinformation creators and posters. ,C00115 - Expose actor and intentions,,,,M003 - daylight,,,,TA08 Pump Priming,D02,"T0041 - Deny involvement
T0048 - Cow online opinion leaders
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0056 - Dedicated channels disseminate information pollution",,information,,,
C00116,Provide proof of involvement,,Build and post information about groups etc's involvement in misinformation incidents. ,C00116 - Provide proof of involvement,,,,M003 - daylight,,,,TA08 Pump Priming,D02,T0041 - Deny involvement,,information,,,
C00117,Downgrade / de-amplify so message is seen by fewer people,,Label promote counter to disinformation,C00117 - Downgrade / de-amplify so message is seen by fewer people,,,,M010 - countermessaging,,,,TA08 Pump Priming,D04,"T0046 - Search engine optimization
T0022 - Conspiracy narratives
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0044 - Seed distortions
T0060 - Continue to amplify
",,information,,,
C00125,Prebunking,,"Produce material in advance of misinformation incidents, by anticipating the narratives used in them, and debunking them. ",C00125 - Prebunking,,,,M001 - resilience,,,,TA09 Exposure,D03,"T0056 - Dedicated channels disseminate information pollution
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0045 - Use fake experts
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
T0010 - Cultivate ignorant agents
",,narrative,,,
C00119,Engage payload and debunk.,,debunk misinformation content.  Provide link to facts. ,C00119 - Engage payload and debunk.,,,,M010 - countermessaging,,,,TA08 Pump Priming,D07,"T0022 - Conspiracy narratives
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0044 - Seed distortions
T0060 - Continue to amplify",,information,,,
C00120,Open dialogue about design of platforms to produce different outcomes,,Redesign platforms and algorithms to reduce the effectiveness of disinformation,C00120 - Open dialogue about design of platforms to produce different outcomes,,,,M007 - metatechnique,,,,TA08 Pump Priming,D07,"T0047 - Muzzle social media as a political force
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution",,action,,,
C00121,Tool transparency and literacy for channels people follow. ,,"Make algorithms in platforms explainable, and visible to people using those platforms. ",C00121 - Tool transparency and literacy for channels people follow. ,,,,M001 - resilience,,,,TA08 Pump Priming,D07,T0043 - Use SMS/ WhatsApp/ Chat app,,information,,,
C00122,Content moderation,,Beware: content moderation misused becomes censorship. ,C00122 - Content moderation,,,,M004 - friction,A031 - social media platform administrator,,,TA09 Exposure,D02,"T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0014 - Create funding campaign
T0015 - Create hashtag
T0016 - Clickbait 
T0017 - Promote online funding
T0018 - Paid targeted ads
T0022 - Conspiracy narratives
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0044 - Seed distortions
T0049 - Flooding 
T0051 - Fabcricate social media comment
T0052 - Tertiary sites amplify news
T0053 - Twitter trolls amplify and manipulate
T0054 - Twitter bots amplify
T0055 - Use hashtag
T0056 - Dedicated channels disseminate information pollution
T0057 - Organise remote rallies and events
T0061 - Sell merchandising
T0060 - Continue to amplify",,action,,,
C00123,Remove or rate limit botnets,,reduce the visibility of known botnets online. ,C00123 - Remove or rate limit botnets,,,,M004 - friction,,,,TA09 Exposure,D03,"T0029 - Manipulate online polls
T0049 - Flooding
T0054 - Twitter bots amplify
T0060 - Continue to amplify",,action,,,
C00124,Don't feed the trolls,,Don't engage with individuals relaying misinformation. ,C00124 - Don't feed the trolls,,,,M004 - friction,"A015 - general public,A021 - media organisation",,,TA09 Exposure,D03,"TA08 - Pump Priming
TA09 - Exposure
T0053 - Twitter trolls amplify and manipulate
T0063 - Social media engagement",,action,,,
C00211,Use humorous counter-narratives,,,C00211 - Use humorous counter-narratives,,,,M010 - countermessaging,,,,TA09 Exposure,D03,"T0027 - Adapt existing narratives
T0022 - Conspiracy narratives
T0028 - Create competing narratives
T0026 - Create fake research
T0021 - Memes 
T0020 - Trial content
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0055 - Use hashtag
T0057 - Organise remote rallies and events",I00004,narrative,,,
C00126,Social media amber alert,,"Create an alert system around disinformation and misinformation artifacts, narratives, and incidents ",C00126 - Social media amber alert,,,,M003 - daylight,,,,TA09 Exposure,D03,"T0056 - Dedicated channels disseminate information pollution
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0045 - Use fake experts
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
T0010 - Cultivate ignorant agents
T0057 - Organise remote rallies and events",,information,,,
C00128,"Create friction by marking content with ridicule or other ""decelerants""",,"Repost or comment on misinformation artifacts, using ridicule or other content to reduce the likelihood of reposting. ","C00128 - Create friction by marking content with ridicule or other ""decelerants""",,,,M009 - dilution,A003 - trusted authority,,,TA09 Exposure,D03,"T0050 - Cheerleading domestic social media ops
T0056 - Dedicated channels disseminate information pollution
T0049 - Flooding 
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0057 - Organise remote rallies and events
T0061 - Sell merchandising",,information,,,
C00129,Use banking to cut off access ,,fiscal sanctions; parallel to counter terrorism,C00129 - Use banking to cut off access ,,,,M014 - reduce resources,,,,TA09 Exposure,D02,"T0057 - Organise remote rallies and events
T0061 - Sell merchandising
T0014 - Create funding campaign
T0017 - Promote online funding
T0018 - Paid targeted ads",,action,,,
C00130,"Mentorship: elders, youth, credit. Learn vicariously.",,Train local influencers in countering misinformation. ,"C00130 - Mentorship: elders, youth, credit. Learn vicariously.",,,,M001 - resilience,,,,TA05 Microtargeting,D07,T0010 - Cultivate ignorant agents,,education,,,
C00131,Seize and analyse botnet servers,,Take botnet servers offline by seizing them. ,C00131 - Seize and analyse botnet servers,,,,M005 - removal,A029 - server administrator,,,TA11 Persistence,D02,"T0049 - Flooding
T0054 - Twitter bots amplify
T0060 - Continue to amplify",,action,,,
C00133,Deplatform Account*,,Note: Similar to Deplatform People but less generic. Perhaps both should be left.,C00133 - Deplatform Account*,,,,M005 - removal,A031 - social media platform administrator,,,TA15 - Establish Social Assets,D03,"TA07 - Channel Selection
TA09 - Exposure
TA10 - Go Physical
T0007 - Create fake Social Media Profiles / Pages / Groups
T0009 - Create fake experts
T0045 - Use fale experts
T0011 - Hijack legitimate account
T0045 - Use fake experts",,action,,,
C00135,Deplatform message groups and/or message boards,,Merged two rows here. ,C00135 - Deplatform message groups and/or message boards,,,,M005 - removal,A031 - social media platform administrator,,,TA15 Establish Social Assets,D03,"TA07 - Channel Selection
TA09 - Exposure
TA10 - Go Physical
T0007 - Create fake Social Media Profiles / Pages / Groups
T0043 - Use SMS/ WhatsApp/ Chat apps",,action,,,
C00136,Microtarget most likely targets then send them countermessages,,"Find communities likely to be targetted by misinformation campaigns, and send them countermessages or pointers to information sources. ",C00136 - Microtarget most likely targets then send them countermessages,,,,M010 - countermessaging,,,,TA08 Pump Priming,D03,"TA08 - Pump Priming
TA09 - Exposure
TA10 - Go Physical
T0010 - Cultivate ignorant agents
T0020 - Trial content
T0063 - Social media engagement",,information,,,
C00138,Spam domestic actors with lawsuits,,"File multiple lawsuits against known misinformation creators and posters, to distract them from disinformation creation. ",C00138 - Spam domestic actors with lawsuits,,,,M014 - reduce resources,,,,TA11 Persistence,D03,"T0060 - Continue to amplify
T0056 - Dedicated channels disseminate information pollution",,regulation,,,
C00139,Weaponise youtube content matrices,,God knows what this is. Keeping temporarily in case we work it out. ,C00139 - Weaponise youtube content matrices,,,,M004 - friction,,,,TA11 Persistence,D03,,,information,,,
C00140,"""Bomb"" link shorteners with lots of calls",,"Applies to most of the content used by exposure techniques except ""T0055 - Use hashtag”. Applies to analytics","C00140 - ""Bomb"" link shorteners with lots of calls",,,,M008 - data pollution,,,,TA12 Measure Effectiveness,D03,"TA05 - Microtargeting
TA09 - Exposure*
TA10 - Go Physical",,action,,,
C00142,Platform adds warning label and decision point when sharing content,,"Includes “this has been disproved: do you want to forward it”. Includes “""Hey this story is old"" popup when messaging with old URL” - this assumes that this technique is based on visits to an URL shortener or a captured news site that can publish a message of our choice.  Includes “mark clickbait visually”. ",C00142 - Platform adds warning label and decision point when sharing content,,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA06 Develop Content,D04,"TA05 - Microtargeting
TA09 - Exposure
TA10 - Go Physical
TA11 - Persistence
T0016 - Clickbait
",,information,,,
C00143,(botnet) DMCA takedown requests to waste group time,,Use copyright infringement claims to remove videos etc. ,C00143 - (botnet) DMCA takedown requests to waste group time,,,,M013 - targeting,"A015 - general public,A014 - elves",,,TA11 Persistence,D04,"T0060 - Continue to amplify
T0058 - Legacy web content
T0024 - Create fake videos and images",,regulation,,,
C00144,Buy out troll farm employees / offer them jobs,,Degrade the infrastructure. Could e.g. pay to not act for 30 days.  Not recommended,C00144 - Buy out troll farm employees / offer them jobs,,,,M014 - reduce resources,,,,TA02 Objective Planning,D04,T0053 - Twitter trolls amplify and manipulate,,action,,,
C00147,Make amplification of social media posts expire (e.g. can't like/ retweet after n days),,"Stop new community activity (likes, comments) on old social media posts.  ",C00147 - Make amplification of social media posts expire (e.g. can't like/ retweet after n days),,,,M004 - friction,A031 - social media platform administrator,R004 - platform algorithms,,TA09 Exposure,D03,T0060 - Continue to amplify,,action,,,
C00148,Add random links to network graphs,,"If creators are using network analysis to determine how to attack networks, then adding random extra links to those networks might throw that analysis out enough to change attack outcomes. Unsure which DISARM techniques.",C00148 - Add random links to network graphs,,,,M008 - data pollution,A031 - social media platform administrator,R004 - platform algorithms,,TA12 Measure Effectiveness,D04,"T0062 - Message reach
T0063 - Social media engagement
",,action,,,
C00149,Poison the monitoring & evaluation data,,Includes Pollute the AB-testing data feeds: Polluting A/B testing requires knowledge of MOEs and MOPs. A/B testing must be caught early when there is relatively little data available so infiltration of TAs and understanding of how content is migrated from testing to larger audiences is fundamental.,C00149 - Poison the monitoring & evaluation data,,,,M008 - data pollution,,,,TA12 Measure Effectiveness,D04,"TA12 - Measure Effectiveness
T0020 - Trial content
T0046 - Search Engine Optimization
T0057 - Organise  remote rallies and events
T0063 - Social media engagement",,action,,,
C00153,Take pre-emptive action against actors' infrastructure,,"Align offensive cyber action with information operations and counter disinformation approaches, where appropriate.",C00153 - Take pre-emptive action against actors' infrastructure,,,,M013 - targeting,A027 - information security,,,TA01 Strategic Planning,D03,"T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0011 - Hijack legitimate account
T0013 - Create fake websites
T0014 - Create funding campaign
T0017 - Promote online funding
T0018 - Paid targeted ads
T0056 - Dedicated channels disseminate information pollution
T0049 - Flooding 
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0058 - Legacy web content
T0057 - Organise remote rallies and events
T0061 - Sell merchandising",,action,,,
C00154,Ask media not to report false information,,"Train media to spot and respond to misinformation, and ask them not to post or transmit misinformation they've found. ",C00154 - Ask media not to report false information,,,,M005 - removal,A021 - media organisation,,,TA08 Pump Priming,D02,"T0039 - Bait legitimate inffluencers
T0048 - Cow online opinion leaders
T0045 - Use fake experts",I00022,information,,,
C00155,Ban incident actors from funding sites,,Ban misinformation creators and posters from funding sites,C00155 - Ban incident actors from funding sites,,,,M005 - removal,A025 - funding site admin,,,TA15 - Establish Social Assets,D02,"T0014 - Create funding campaign
T0017 - Promote online funding",I00002,action,,,
C00156,Better tell your country or organization story,,"Civil engagement activities conducted on the part of EFP forces.  NATO should likewise provide support and training, where needed, to local public affairs and other communication personnel. Local government and military public affairs personnel can play their part in creating and disseminating entertaining and sharable content that supports the EFP mission. ",C00156 - Better tell your country or organization story,,,,M010 - countermessaging,"A018 - government,A019 - military",,,TA02 Objective Planning,D03,"T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
T0010 - Cultivate ignorant agents",,information,,,
C00159,Have a disinformation response plan,,"e.g. Create a campaign plan and toolkit for competition short of armed conflict (this used to be called “the grey zone”). The campaign plan should account for own vulnerabilities and strengths, and not over-rely on any one tool of statecraft or line of effort.  It will identify and employ a broad spectrum of national power to deter, compete, and counter (where necessary) other countries’ approaches, and will include understanding of own capabilities, capabilities of disinformation creators, and international standards of conduct to compete in, shrink the size, and ultimately deter use of competition short of armed conflict.",C00159 - Have a disinformation response plan,,,,M007 - metatechnique,,,,TA01 Strategic Planning,D03,,,action,,,
C00160,find and train influencers,,"Identify key influencers (e.g. use network analysis), then reach out to identified users and offer support, through either training or resources.",C00160 - find and train influencers,,,,M001 - resilience,"A001 - data scientist,A016 - influencer",,,TA15 - Establish Social Assets,D02,"T0039 - Bait legitimate inffluencers
T0010 - Cultivate ignorant agents
T0048 - Cow online opinion leaders",,education,,,
C00161,Coalition Building with stakeholders and Third-Party Inducements,,"Advance coalitions across borders and sectors, spanning public and private, as well as foreign and domestic, divides. Improve mechanisms to collaborate, share information, and develop coordinated approaches with the private sector at home and allies and partners abroad.",C00161 - Coalition Building with stakeholders and Third-Party Inducements,,,,M007 - metatechnique,,,,TA01 Strategic Planning,D07,"T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives",,action,,,
C00162,Unravel/target the Potemkin villages,,"Kremlin’s narrative spin extends through constellations of “civil society” organizations, political parties, churches, and other actors. Moscow leverages think tanks, human rights groups, election observers, Eurasianist integration groups, and orthodox groups. A collection of Russian civil society organizations, such as the Federal Agency for the Commonwealth of Independent States Affairs, Compatriots Living Abroad, and International Humanitarian Cooperation, together receive at least US$100 million per year, in addition to government-organized nongovernmental organizations (NGOs), at least 150 of which are funded by Russian presidential grants totaling US$70 million per year.",C00162 - Unravel/target the Potemkin villages,,,,M013 - targeting,,,,TA15 Establish Social Assets,D03,"T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
T0039 - Bait legitimate inffluencers
T0052 - Tertiary sites amplify news
T0056 - Dedicated channels disseminnate information pollution
T0050 - Cheerleading domemstic social media ops",,information,,,
C00164,compatriot policy,,"protect the interests of this population and, more importantly, influence the population to support pro-Russia causes and effectively influence the politics of its neighbors",C00164 - compatriot policy,,,,M013 - targeting,,,,TA02 Objective Planning,D03,"T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
",,action,,,
C00165,Ensure integrity of official documents,,"e.g. for leaked legal documents, use court motions to limit future discovery actions",C00165 - Ensure integrity of official documents,,,,M004 - friction,,,,TA06 Develop Content,D02,T0025 - leak altered documents,I00015,information,,,
C00169,develop a creative content hub,,"international donors will donate to a basket fund that will pay a committee of local experts who will, in turn, manage and distribute the money to Russian-language producers and broadcasters that pitch various projects.",C00169 - develop a creative content hub,,,,M010 - countermessaging,,,,TA02 Objective Planning,D03,"T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0002 - Facilitate State Propaganda
T0003 - Leverage existing narratives
T0004 - Competing narratives
T0039 - Bait legitimate inffluencers",,action,,,
C00170,elevate information as a critical domain of statecraft,,"Shift from reactive to proactive response, with priority on sharing relevant information with the public and mobilizing private-sector engagement. Recent advances in data-driven technologies have elevated information as a source of power to influence the political and economic environment, to foster economic growth, to enable a decision-making advantage over competitors, and to communicate securely and quickly.",C00170 - elevate information as a critical domain of statecraft,,,,M007 - metatechnique,,,,TA01 Strategic Planning,D03,,,action,,,
C00172,social media source removal,,"Removing accounts, pages, groups, e.g. facebook page removal",C00172 - social media source removal,,,,M005 - removal,A031 - social media platform administrator,,,TA15 Establish Social Assets,D02,"T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0013 - Create fake websites
",I00035,action,,,
C00174,Create a healthier news environment,,"Free and fair press: create bipartisan, patriotic commitment to press freedom.  Note difference between news and editorialising.  Build alternative news sources: create alternative local-language news sources to counter local-language propaganda outlets. Delegitimize the 24 hour news cycle.  includes Provide an alternative to disinformation content by expanding and improving local content: Develop content that can displace geopolitically-motivated narratives in the entire media environment, both new and old media alike.",C00174 - Create a healthier news environment,,,,"M007 - metatechnique, M002 - diversion",A021 - media organisation,,,TA01 Strategic Planning,D02,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0045 - Use fake experts
T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0044 - Seed distortions",,action,,,
C00176,Improve Coordination amongst stakeholders: public and private,,"Coordinated disinformation challenges are increasingly multidisciplinary, there are few organizations within the national security structures that are equipped with the broad-spectrum capability to effectively counter large-scale conflict short of war tactics in real-time. Institutional hurdles currently impede diverse subject matter experts, hailing from outside of the traditional national security and foreign policy disciplines (e.g., physical science, engineering, media, legal, and economics fields), from contributing to the direct development of national security countermeasures to emerging conflict short of war threat vectors. A Cognitive Security Action Group (CSAG), akin to the Counterterrorism Security Group (CSG), could drive interagency alignment across equivalents of DHS, DoS, DoD, Intelligence Community, and other implementing agencies, in areas including strategic narrative, and the nexus of cyber and information operations. ",C00176 - Improve Coordination amongst stakeholders: public and private,,,,M007 - metatechnique,,,,TA01 Strategic Planning,D07,"T0009 - Create fake experts
T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0013 - Create fake websites
T0014 - Create funding campaign
T0015 - Create hashtag
T0016 - Clickbait 
T0017 - Promote online funding
T0018 - Paid targeted ads
T0021 - Memes 
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0043 - Use SMS/WhatsApp/ Chat apps
T0056 - Dedicated channels disseminate information pollution
T0051 - Fabricate social media comment
T0049 - Flooding 
T0052 - Tertiary sites amplify news
T0054 - Twitter bots amplify
T0053 - Twitter trolls amplify and manipulate
T0055 - Use hashtag
T0058 - Legacy web content
T0057 - Organise remote rallies and events
T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0003 - Leverage existing narratives
T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0061 - Sell merchandising",,action,,,
C00178,Fill information voids with non-disinformation content,,"1) Pollute the data voids with wholesome content (Kittens! Babyshark!). 2) fill data voids with relevant information, e.g. increase Russian-language programming in areas subject to Russian disinformation.  ",C00178 - Fill information voids with non-disinformation content,,,,"M009 - dilution, M008 - data pollution",,,,TA05 Microtargeting,D04,"T0016 - Clickbait 
T0017 - Promote online funding
T0018 - Paid targeted ads
T0020 - Trial content",,information,,,
C00182,Redirection / malware detection/ remediation,,"Detect redirction or malware, then quarantine or delete.  ",C00182 - Redirection / malware detection/ remediation,,,,M005 - removal,A027 - information security,,,TA09 Exposure,D02,"T0011 - Hijack legitimate account
T0054 - Twitter bots amplify",,action,,,
C00184,Media exposure,,highlight misinformation activities and actors in media,C00184 - Media exposure,,,,M003 - daylight,,,,TA08 Pump Priming,D04,"T0045 - Use fake experts
T0055 - Use hashtag
T0039 - Bait legitimate influencers
T0041 - Deny involvement
T0044 - Seed distortions
T0045 - Use fake experts
T0010 - Cultivate ignorant agents","I00010,I00015,I00032,I00044",information,,,
C00188,Newsroom/Journalist training to counter influence moves,,"Includes SEO influence.   Includes promotion of a “higher standard of journalism”: journalism training “would be helpful, especially for the online community.  Includes Strengthen local media: Improve effectiveness of local media outlets. ",C00188 - Newsroom/Journalist training to counter influence moves,,,,M001 - resilience,"A021 - media organisation,A006 - educator",,,TA08 Pump Priming,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0003 - Leverage existing narratives
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0045 - Use fake experts
T0008 - Create fake or imposter news sites
T0010 - Cultivate ignorant agents
T0039 - Bait legitimate influencers
T0046 - Search Engine Optimization
",,education,,,
C00189,Ensure that platforms are taking down flagged accounts,,"Use ongoing analysis/monitoring of ""flagged"" profiles.  Confirm whether platforms are actively removing flagged accounts, and raise pressure via e.g. government organizations to encourage removal",C00189 - Ensure that platforms are taking down flagged accounts,,,,M003 - daylight,,,,TA15 - Establish Social Assets,D06,"T0008 - Create fake or imposter news sites
T0007 - Create fake Social Media Profiles / Pages / Groups
T0011 - Hijack legitimate account
T0014 - Create funding campaign
T0009 - Create fake experts",,action,,,
C00190,open engagement with civil society,,"Government open engagement with civil society as an independent check on government action and messaging. Government seeks to coordinate and synchronize narrative themes with allies and partners while calibrating action in cases where elements in these countries may have been co-opted by competitor nations. Includes “fight in the light”: Use leadership in the arts, entertainment, and media to highlight and build on fundamental tenets of democracy.",C00190 - open engagement with civil society,,,,M001 - resilience,A015 - general public,,,TA01 Strategic Planning,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0003 - Leverage existing narratives
T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0025 - Leak altered documents",,action,,,
C00195,Redirect searches away from disinformation or extremist content ,,Use Google AdWords to identify instances in which people search Google about particular fake-news stories or propaganda themes. Includes Monetize centrist SEO by subsidizing the difference in greater clicks towards extremist content. ,C00195 - Redirect searches away from disinformation or extremist content ,,,,M002 - diversion,,R002 - funding,,TA07 Channel Selection,D02,"T0010 - Cultivate ignorant agents
T0016 - Clickbait 
T0018 - Paid targeted ads
T0022 - Conspiracy narratives
T0027 - Adapt existing narratives
T0025 - Leak altered documents
T0024 - Create fake videos and images
T0026 - Create fake research
T0045 - Use fake experts
T0046 - Search engine optimization
T0055 - Use hashtag",,information,,,
C00197,remove suspicious accounts,,"Standard reporting for false profiles (identity issues).  Includes detecting hijacked accounts and reallocating them - if possible, back to original owners. ",C00197 - remove suspicious accounts,,,,M005 - removal,"A031 - social media platform administrator,A004 activist",R003 - money,,TA15 - Establish Social Assets,D02,"T0009 - Create fake experts
T0007 - Create fake Social Media Profiles / Pages / Groups
T0011 - Hijack accounts",I00022,action,,,
C00200,Respected figure (influencer) disavows misinfo,,FIXIT: standardize language used for influencer/ respected figure. ,C00200 - Respected figure (influencer) disavows misinfo,,,,M010 - countermessaging,A016 - influencer,,,TA09 Exposure,D03,"T0010 - Cultivate ignorant agents
T0027 - Adapt existing narratives
T0022 - Conspiracy narratives
T0045 - Use fake experts
T0025 - Leak altered documents",I00044,information,,,
C00202,Set data 'honeytraps',,Set honeytraps in content likely to be accessed for disinformation. ,C00202 - Set data 'honeytraps',,,,M002 - diversion,,,,TA06 Develop Content,D02,T0025 - leak altered documents,"I00004,I00022",action,,,
C00203,Stop offering press credentials to propaganda outlets,,Remove access to official press events from known misinformation actors. ,C00203 - Stop offering press credentials to propaganda outlets,,,,M004 - friction,A018 - government,,,TA15 Establish Social Assets,D03,"T0010 - Cultivate ignorant agents
T0027 - Adapt existing narratives
T0022 - Conspiracy narratives
T0028 - Create competing narratives
T0039 - Bait legitimate influencers
T0045 - Use fake experts
T0056 - Dedicated channels disseminate information pollution
T0052 - Tertiary sites amplify news",I00022,action,,,
C00205,strong dialogue between the federal government and private sector to encourage better reporting,,Increase civic resilience by partnering with business community to combat gray zone threats and ensuring adequate reporting and enforcement mechanisms. ,C00205 - strong dialogue between the federal government and private sector to encourage better reporting,,,,M007 - metatechnique,"A018 - government,A033 - social media platform owner,",,,TA01 Strategic Planning,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0003 - Leverage existing narratives
T0022 - Conspiracy narratives
T0025 - Leak altered documents
T0027 - Adapt existing narratives",,action,,,
C00207,Run a competing disinformation campaign - not recommended,,,C00207 - Run a competing disinformation campaign - not recommended,,,,M013 - targeting,"A018 - government,A033 - social media platform owner",,,TA02 Objective Planning,D07,,I00042,action,,,
C00212,build public resilience by making civil society more vibrant,,"Increase public service experience, and support wider civics and history education.",C00212 - build public resilience by making civil society more vibrant,,,,M001 - resilience,"A006 - educator,A018 - government",,,TA01 Strategic Planning,D03,"T0001 - 5Ds (dismiss, distort, distract, dismay, divide)
T0003 - Leverage existing narratives
T0010 - Cultivate ignorant agents
T0022 - Conspiracy narratives",,action,,,
C00216,Use advertiser controls to stem flow of funds to bad actors,,Prevent ad revenue going to disinformation domains,C00216 - Use advertiser controls to stem flow of funds to bad actors,,,,M014 - reduce resources,A023 - adtech provider,,,TA05 Microtargeting,D02,"T0014 - Create funding campaign
T0016 - Clickbait 
T0017 - Promote online funding
T0061 - Sell merchandising
T0018 - Paid targeted ads
T0057 - Organise remote rallies and events",,action,,,
C00219,Add metadata to content that’s out of the control of disinformation creators,,"Steganography. Adding date, signatures etc to stop issue of photo relabelling etc. ",C00219 - Add metadata to content that’s out of the control of disinformation creators,,,,M003 - daylight,,,,TA06 Develop Content,D04,"T0024 - Create fake videos and images
T0026 - Create fake research
T0025 - Leak altered documents",,information,,,
C00220,Develop a monitoring and intelligence plan,,"Create a plan for misinformation and disinformation response, before it's needed.  Include connections / contacts needed, expected counteremessages etc. ",C00220 - Develop a monitoring and intelligence plan,,,,M007 - metatechnique,,,,TA01 Strategic Planning,D03,,,action,,,
C00221,"Run a disinformation red team, and design mitigation factors",,"Include PACE plans - Primary, Alternate, Contingency, Emergency","C00221 - Run a disinformation red team, and design mitigation factors",,,,M007 - metatechnique,,,,TA01 Strategic Planning,D03,,,action,,,
C00222,Tabletop simulations,,"Simulate misinformation and disinformation campaigns, and responses to them, before campaigns happen. ",C00222 - Tabletop simulations,,,,M007 - metatechnique,,,,TA02 Objective Planning,D03,,,education,,,
C00223,Strengthen Trust in social media platforms,,Improve trust in the misinformation responses from social media and other platforms.  Examples include creating greater transparancy on their actions and algorithms. ,C00223 - Strengthen Trust in social media platforms,,,,M001 - resilience,,,,TA01 Strategic Planning,D03,,,action,,,
PB00001,Game Mechanics: show examples of fake news and train the user to identify them on the basis of various types of indicators,,,,,,,,,,,,,,,,C00011,,
PB00002,Game mechanics: use a crowd-sourced mechanism so that the public can categorize newly spreading news sources or articles a la Re-Captcha,,,,,,,,,,,,,,,,C00011,,
PB00003,Develop a regulatory body like the CFPB to regulate and enforce regulation for digital organizations. ,,,,,,,,,,,,,,,,C00012,,
PB00004,Government regulation,,,,,,,,,,,,,,,,C00012,,
PB00005,Government shutdown. ,,,,,,,,,,,,,,,,C00012,,
PB00006,Use a media campaign to promote in-group to out-group in person communication / activities . ,,,,,,,,,,,,,,,,C00017,,
PB00007,"Spread Infographics & Training Material teaching ways to identify and counter divisive rhetorical techniques and content, by stimulating their sense of outrage at being manipulated. Show them how to address the rhetorical technique rather than the content",,,,,,,,,,,,,,,,C00019,,
PB00008,Twitter hashtags & paid advertising,,,,,,,,,,,,,,,,C00019,,
PB00009,Teach people to identify non-civil/unconstructive conversations and call them out,,,,,,,,,,,,,,,,C00019,,
PB00010,"Popularize (via memes, infographics) and get the centrists demographic who are tired of polarization to identify such messaging, call it out and display their outrage on the basis of divisive rhetorical techniques rather than merely arguing about the content",,,,,,,,,,,,,,,,C00019,,
PB00011,Recruit respected thought leaders to model behavior,,,,,,,,,,,,,,,,C00027,,
PB00012,Feature established respected thought leaders to model behavior,,,,,,,,,,,,,,,,C00027,,
PB00013,Promote dialog from communities with disparate viewpoints,,,,,,,,,,,,,,,,C00027,,
PB00014,"Establish facilitation guidelines for ""civil"" interaction.",,,,,,,,,,,,,,,,C00027,,
PB00015,Identify ignorant agents (ex: anti-vaxx people willing to pay money to advertise their cause),,,,,,,,,,,,,,,,C00029,,
PB00016,Sell physical merchandise that has instructive counter-effect,,,,,,,,,,,,,,,,C00029,,
PB00017,"Secondary Objective: Obtain real-life identity of ignorant agents, to further disrupt their influence activities",,,,,,,,,,,,,,,,C00029,,
PB00018,Create multiple versions of the narrative and amplify. ,,,,,,,,,,,,,,,,C00031,,
PB00019,"Dissect narrative, piecemeal the components and then amplify",,,,,,,,,,,,,,,,C00031,,
PB00020,Hijack hashtag and redirect conversation to truth based content. ,,,,,,,,,,,,,,,,C00032,,
PB00021,Hijack (man in the middle) redirect from bad content to good content,,,,,,,,,,,,,,,,C00032,,
PB00022,-Discredit via backstopped blogs/websites showing their past activity and opinions as being opposite to their current ingroup,,,,,,,,,,,,,,,,C00036,,
PB00023,Create a trail of commentary about their idea of infiltrating the enemy (current in-group),,,,,,,,,,,,,,,,C00036,,
PB00024,Publicize this by targeting their in-group competitors (ignorant agents),,,,,,,,,,,,,,,,C00036,,
PB00025,Verify personal credentials ,,,,,,,,,,,,,,,,C00040,,
PB00026,Syndicated reputation management (fact-checking syndication),,,,,,,,,,,,,,,,C00040,,
PB00027,Academia ISAO,,,,,,,,,,,,,,,,C00040,,
PB00028,Rate restrict via regulation posting above a statistical threshold,,,,,,,,,,,,,,,,C00044,,
PB00029,Unless account is de-anonymized and advertised as automated messaging,,,,,,,,,,,,,,,,C00044,,
PB00030,"Identify the accounts, the real person's name and shame them on social media.",,,,,,,,,,,,,,,,C00048,,
PB00031,Social media companies remove inactive accounts,,,,,,,,,,,,,,,,C00053,,
PB00032,Account holders remove accounts they're no longer using. ,,,,,,,,,,,,,,,,C00053,,
PB00033,"Influencers encourage people to remove their inactive accounts ""Do you really need that old account"" campaign, world-war-two poster-style. ",,,,,,,,,,,,,,,,C00053,,
PB00034,"Create alternative memorial websites for accounts of deceased people, so their accounts can't be reactivated on 'live' sites. ",,,,,,,,,,,,,,,,C00053,,
PB00035,Educate/scare users on the risks of losing control over a dormant account (would their employer be forgiving if an account associated with the user suddenly starting posting extremist content?).,,,,,,,,,,,,,,,,C00053,,
PB00036,Platform adds a hash of the post to the post metadata and make it publicly available (content addressing). Scrape for duplicate content and deplatform the content/users across affected. In all cases some checks need to prevent deplatforming of highly correlated organic traffic such as a community group copy/pasting their bake sale advert. ,,,,,,,,,,,,,,,,C00074,,
PB00037,Platform adds plagiarism score metadata to a post and makes it publicly available. Scrape for duplicate content and deplatform the content/users across affected platforms.,,,,,,,,,,,,,,,,C00074,,
PB00038,Use message hashing and fuzzy hashing to detect identical/similar content.,,,,,,,,,,,,,,,,C00074,,
PB00039,Use plagiarism algorithm to detect similar blog posts.,,,,,,,,,,,,,,,,C00074,,
PB00040,"Use basic web scraping techniques, Google dorks, etc to identify similar head lines, uniques phrases, authorship, embedded links and any other correlating data point.",,,,,,,,,,,,,,,,C00074,,
PB00041,Affected person contacts platform for action,,,,,,,,,,,,,,,,C00098,,
PB00042,"Work with platform to identify active target audiences through finanical data and messaging.
",,,,,,,,,,,,,,,,C00136,,
PB00043,Use a platform's publicly available advertising/targeting capabilities to enumerate a list of possible microtargeted demographics. Compare these to known TAs of past/ongoing influence ops to identify the vulnerable demographics. ,,,,,,,,,,,,,,,,C00136,,
PB00044,"DDoS adversary link shorteners by spamming real links.
",,,,,,,,,,,,,,,,C00140,,
PB00045,Compromise service and reroute links to benign content or counter messaging.,,,,,,,,,,,,,,,,C00140,,
PB00046,Degrade TA engagement using bots; direct the adversary to engage insular bot communities-within-communities rather than the authentic target audience.,,,,,,,,,,,,,,,,C00148,,
PB00047,Degrade MOEs/MOPs by faking inter-community sharing.,,,,,,,,,,,,,,,,C00148,,
PB00048,"Distort TA demographics by posting irrelevant content, misleading demogaphic data, etc.",,,,,,,,,,,,,,,,C00149,,
PB00049,"Work with the media platform to distort publicly available metrics. Can we work with Twitter to get crappy off-brand memes artificially bumped without needing to create fake accounts, etc.?",,,,,,,,,,,,,,,,C00149,,
PB00050,"Use adtech to promote content inconsistent with TA demographics. If the adversary is reverse engineering a groups demographics by analyzing ads placed on the platform/group, by spamming ads for out-group stuff it may distort analysis of the group.",,,,,,,,,,,,,,,,C00149,,
PB00051,"Distort Google Trends and other publicly available source of metrics using bots, cyborgs, adtech.",,,,,,,,,,,,,,,,C00149,,
PB00052,Distort TA emotional response to content/narratives.,,,,,,,,,,,,,,,,C00149,,
PB00053,Promote damp squibs. Within a known TA promote/inflate crappy off-brand memes which are unlikley to resonate.,,,,,,,,,,,,,,,,C00149,,
PB00054,"Detect early trending/engagement and undermine the content by responding with 5Ds, toxic community behaviour, satirical responses, etc.",,,,,,,,,,,,,,,,C00149,,
PB00055,"If adtech is used, fake clicks and engagements on the content.",,,,,,,,,,,,,,,,C00149,,
PB00056,Elected officials lead return to First Amendment norms that embrace free and fair media as central to democracy.,,,,,,,,,,,,,,,,C00174,,
PB00057,"TechCamp bringing together local journalists, with a several-day training program that includes a sponsored yearlong investigative project",,,,,,,,,,,,,,,,C00188,,
PB00058,"Create a standard reporting format and method for social platforms for reporting false accounts. 
",,,,,,,,,,,,,,,,C00197,,
PB00059,Determine whether account might be compromised,,"Questions: - Is the account compromised? 
- Is it known to be associated with threat actors 
- common/random name 
- Names violate terms of service 
- Dormant account 
- Change of country IP
- Social network growth patterns (number of friends etc) 
- Evidence of linguistic artifacts (multiple fingerprints, terms/idiosyncrasies )
- Community vs. narrative vs. individuals ",,,,,,,,,,,,,,C00197,,
PB00060,Report suspected bots.,,,,,,,,,,,,,,,,C00197,,
PB00061,"Report ToS violations. In all playbooks the platform must force user verification, credential reset and enable MFA. Suspend the account if it cannot be verified.",,,,,,,,,,,,,,,,C00197,,
PB00062,Use sites like https://haveibeenpwned.com to detect compromised and at risk user accounts. ,,,,,,,,,,,,,,,,C00197,,
PB00063,"Monitor for unusual account usage (use of VPN, new geographic location, unusual usage hours, etc). ",,,,,,,,,,,,,,,,C00197,,
PB00064,Detect sudden deviation in user sentiment such as suddenly dropping hashtags linked to extremist content.,,,,,,,,,,,,,,,,C00197,,
PB00065,"Purchase ""likes"", ""retweets"" and other vehicles which identify a bot and/or hijacked account. Ban the account.",,,,,,,,,,,,,,,,C00197,,
PB00066,"Detect hijacked account and spam their posts. ""OP is a known disinformation bot. http://link.to.proof[.]com""",,,,,,,,,,,,,,,,C00197,,
PB00067,Add date and source to images,,,,,,,,,,,,,,,,C00219,,
PB00068,"Develop a baseline virality per platform, monitor trends, trigger alert for anomalies.",,,,,,,,,,,,,,,,F00002,,
PB00069,"Destroy Desire to Work for Propaganda Businesses
",,"-Identify non-committed actors (ie. IRA 2$/h employees)
-Identify where they reside (ie. postal code level)
-Send a viral message that clarifies the risk of working in influence ops. ",,,,,,,,,,,,,,F00003,,
PB00070,"Hack personal accounts
-Send inflammatory messages on their behalf",,,,,,,,,,,,,,,,F00003,,
PB00071,Identify target and entice individual to reveal insider information,,,,,,,,,,,,,,,,F00004,,
PB00072,"-Model communities on the basis of behavior and identity, etc
-Model different online behaviors in terms of how these groups interact with propaganda
-Model how these group-based behaviors are affected by the tech platform they are using
-This research can feed into later-stage playbooks to adapt them to communities/platforms",,,,,,,,,,,,,,,,F00005,,
PB00073,Model each major platform,,"Determine:
a) Moderation Method (global, subcommunity level, none -ie. twitter, reddit, 8chan)
b) Access Model (friend request, open, real-life identity)
c) Communication Model (global, friends only, subcommunity, hybrid)
Determine how the combination of the above (and other characteristics) allow different technical methods to communicate and influence various audiences
This will allow to adapt playbooks to specific platforms",,,,,,,,,,,,,,F00006,,
PB00074,"- Trace money and financing 
- Trace connections to known operations",,,,,,,,,,,,,,,,F00013,,
PB00075,"- Hashes
- Data voids
- User handles 
- Domains + link shortener
- TinEye For video (visual artifact)",,,,,,,,,,,,,,,,F00014,,
PB00076,Create standard scoring for emptional content,,,,,,,,,,,,,,,,F00017,,
PB00077,"Ad tech 
- De-platform funding sites 
- Blockchain transaction 
- Sell items
- Identify manufacturers 
- Pay to play meetings ",,,,,,,,,,,,,,,,F00018,,
PB00078,"Identify ad tech on platforms 
- Selling merch? 
- Financial platform
- Bitcoin etc.. .",,,,,,,,,,,,,,,,F00018,,
PB00079,"Identify re-use of ads
",,"Look at Ad trackers, Tracking ids, Tracking ads, Re-use of as features (language, name, themes, plug-in, re-use/versions)",,,,,,,,,,,,,,F00018,,
PB00080,track funding sources,,,,,,,,,,,,,,,,F00018,,
PB00081,Build and update a model bot behaviour. ,,,,,,,,,,,,,,,,F00077,,
PB00082,Build network of companies that model / rate bots. Build standards around data sharing and exchange,,,,,,,,,,,,,,,,F00077,,
PB00083,"Build a reporting system for the public, so they can report disinformation artefacts and have them available to channels etc for action. ",,,,,,,,,,,,,,,,F00092,,
D01,Detect,,"Discover or discern the existence, presence, or fact of an intrusion into information systems.",D01 - Detect,,,,,,,,,,,,,,,
D02,Deny,,"Prevent disinformation creators from accessing and using critical information, systems, and services. Deny is for an indefinite time period. ",D02 - Deny,,,,,,,,,,,,,,,
D03,Disrupt,,"Completely break or interrupt the flow of information, for a fixed amount of time. (Deny, for a limited time period).  Not allowing any efficacy, for a short amount of time. ",D03 - Disrupt,,,,,,,,,,,,,,,
D04,Degrade,,"Reduce the effectiveness or efficiency of disinformation creators’ command and control or communications systems, and information collection efforts or means, either indefinitely, or for a limited time period. ",D04 - Degrade,,,,,,,,,,,,,,,
D05,Deceive,,Cause a person to believe what is not true. military deception seeks to mislead adversary decision makers by manipulating their perception of reality.,D05 - Deceive,,,,,,,,,,,,,,,
D06,Destroy,,"Damage a system or entity so badly that it cannot perform any function or be restored to a usable condition without being entirely rebuilt. Destroy is permanent, e.g. you can rebuild a website, but it’s not the same website. ",D06 - Destroy,,,,,,,,,,,,,,,
D07,Deter,,Discourage.,D07 - Deter,,,,,,,,,,,,,,,
M001,resilience,,Increase the resilience to disinformation of the end subjects or other parts of the underlying system,M001 - resilience,,,,,,,,,,,,,,,
M002,diversion,,"Create alternative channels, messages etc in disinformation-prone systems",M002 - diversion,,,,,,,,,,,,,,,
M003,daylight,,"Make disinformation objects, mechanisms, messaging etc visible",M003 - daylight,,,,,,,,,,,,,,,
M004,friction,,"Slow down transmission or uptake of disinformation objects, messaging etc",M004 - friction,,,,,,,,,,,,,,,
M005,removal,,Remove disinformation objects from the system,M005 - removal,,,,,,,,,,,,,,,
M006,scoring,,Use a rating system,M006 - scoring,,,,,,,,,,,,,,,
M007,metatechnique,,,M007 - metatechnique,,,,,,,,,,,,,,,
M008,data pollution,,Add artefacts to the underlying system that deliberately confound disinformation monitoring,M008 - data pollution,,,,,,,,,,,,,,,
M009,dilution,,Dilute disinformation artefacts and messaging with other content (kittens!),M009 - dilution,,,,,,,,,,,,,,,
M010,countermessaging,,Create and distribute alternative messages to disinformation,M010 - countermessaging,,,,,,,,,,,,,,,
M011,verification,,"Verify objects, content, connections etc. Includes fact-checking",M011 - verification,,,,,,,,,,,,,,,
M012,cleaning,,Clean unneeded resources (accounts etc) from the underlying system so they can't be used in disinformation,M012 - cleaning,,,,,,,,,,,,,,,
M013,targeting,,Target the components of a disinformation campaign,M013 - targeting,,,,,,,,,,,,,,,
M014,reduce resources,,Reduce the resources available to disinformation creators,M014 - reduce resources,,,,,,,,,,,,,,,
A001,data scientist ,,"Person who can wrangle data, implement machine learning algorithms etc",A001 - data scientist ,,,,,,,,,,,,,,"S001, S002, S003, S004, S005, S006, S007, S008, S009, S010","FW01, FW02"
A002,target,,Person being targeted by disinformation campaign,A002 - target,,,,,,,,,,,,,,"S001, S002, S003, S004, S005, S006, S007, S008, S009, S010",FW02
A003,trusted authority ,,Influencer,A003 - trusted authority ,,,,,,,,,,,,,,"S001, S002, S003, S004, S005, S006, S007, S008, S009, S010","FW01, FW02"
A004,activist,,,A004 - activist,,,,,,,,,,,,,,S002,FW02
A005,community group,,,A005 - community group,,,,,,,,,,,,,,S002,FW02
A006,educator,,,A006 - educator,,,,,,,,,,,,,,S002,FW02
A007,factchecker,,Someone with the skills to verify whether information posted is factual,A007 - factchecker,,,,,,,,,,,,,,S002,FW02
A008,library,,,A008 - library,,,,,,,,,,,,,,S002,FW02
A009,NGO,,,A009 - NGO,,,,,,,,,,,,,,S002,FW02
A010,religious organisation ,,,A010 - religious organisation ,,,,,,,,,,,,,,S002,FW02
A011,school ,,,A011 - school ,,,,,,,,,,,,,,S002,FW02
A012,account owner,,Anyone who owns an account online,A012 - account owner,,,,,,,,,,,,,,S006,"FW01
FW02"
A013,content creator ,,,A013 - content creator ,,,,,,,,,,,,,,S006,"FW01
FW02"
A014,elves,,,A014 - elves,,,,,,,,,,,,,,S006,FW02
A015,general public,,,A015 - general public,,,,,,,,,,,,,,S006,FW02
A016,influencer,,,A016 - influencer,,,,,,,,,,,,,,S006,"FW01
FW02"
A017,coordinating body,,For example the DHS,A017 - coordinating body,,,,,,,,,,,,,,S003,FW02
A018,government ,,Government agencies,A018 - government ,,,,,,,,,,,,,,S003,"FW01
FW02"
A019,military ,,,A019 - military ,,,,,,,,,,,,,,S003,FW02
A020,policy maker,,,A020 - policy maker,,,,,,,,,,,,,,S003,FW02
A021,media organisation,,,A021 - media organisation,,,,,,,,,,,,,,S010,"FW01
FW02"
A022,company,,,A022 - company,,,,,,,,,,,,,,S009,FW02
A023,adtech provider,,,A023 - adtech provider,,,,,,,,,,,,,,S008,FW02
A024,developer,,,A024 - developer,,,,,,,,,,,,,,S008,FW02
A025,funding_site_admin,,Funding site admin,A025 - funding_site_admin,,,,,,,,,,,,,,S008,FW02
A026,games designer,,,A026 - games designer,,,,,,,,,,,,,,S008,"FW01, FW02"
A027,information security,,,A027 - information security,,,,,,,,,,,,,,S008,FW02
A028,platform administrator,,,A028 - platform administrator,,,,,,,,,,,,,,S008,FW02
A029,server admininistrator ,,,A029 - server admininistrator ,,,,,,,,,,,,,,S008,FW02
A030,platforms ,,,A030 - platforms ,,,,,,,,,,,,,,S007,FW02
A031,social media platform adminstrator,,"Person with the authority to make changes to algorithms, take down content etc. ",A031 - social media platform adminstrator,,,,,,,,,,,,,,S007,FW02
A032,social media platform outreach ,,,A032 - social media platform outreach ,,,,,,,,,,,,,,S007,FW02
A033,social media platform owner,,Person with authority to make changes to a social media company’s business model,A033 - social media platform owner,,,,,,,,,,,,,,S007,FW02
S001,Nonprofit,,,S001 - Nonprofit,,,,,,,,,,,,,,,
S002,Civil Society,,,S002 - Civil Society,,,,,,,,,,,,,,,
S003,Government,,,S003 - Government,,,,,,,,,,,,,,,
S004,Academic,,,S004 - Academic,,,,,,,,,,,,,,,
S005,Activist,,,S005 - Activist,,,,,,,,,,,,,,,
S006,General Public,,,S006 - General Public,,,,,,,,,,,,,,,
S007,Social Media Company,,,S007 - Social Media Company,,,,,,,,,,,,,,,
S008,Other Tech Company,,,S008 - Other Tech Company,,,,,,,,,,,,,,,
S009,Other Company,,,S009 - Other Company,,,,,,,,,,,,,,,
S010,Media,,,S010 - Media,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,
R001,datastreams ,,Access to streaming data,R001 - datastreams ,,,,,,,,,,,,,,,
R002,funding ,,"Money to keep the lights on: for resources, time etc",R002 - funding ,,,,,,,,,,,,,,,
R003,money ,,Money for specific resources,R003 - money ,,,,,,,,,,,,,,,
R004,platform algorithms ,,Access to the algorithms used in a platform.,R004 - platform algorithms ,,,,,,,,,,,,,,,
R005,slang translation,,Translations of slang terms,R005 - slang translation,,,,,,,,,,,,,,,
R006,disinformation datasets,,Access to datasets containing disinformation,R006 - disinformation datasets,,,,,,,,,,,,,,,
MP00001,Likes,,,MP00001,,,,,,,,,,,,,,,
MP00002,Shares,,,MP00002,,,,,,,,,,,,,,,
MP00003,Comments,,,MP00003,,,,,,,,,,,,,,,
MP00004,Follows,,,MP00004,,,,,,,,,,,,,,,
MP00005,Retweets,,,MP00005,,,,,,,,,,,,,,,
MP00006,Clicks,,,MP00006,,,,,,,,,,,,,,,
MP00007,Active Followers,,,MP00007,,,,,,,,,,,,,,,
MP00008,Relevance Score,,see: facebook relevance algo,MP00008,,,,,,,,,,,,,,,
MP00009,Follwers vs. Following Ratio,,,MP00009,,,,,,,,,,,,,,,
MP00010,Inter-Community Posting ,,4chan to Reddit,MP00010,,,,,,,,,,,,,,,
MP00011,Intra-Community Posting,,crossposting between boards,MP00011,,,,,,,,,,,,,,,
MP00012,Reach vs. Impressions,,,MP00012,,,,,,,,,,,,,,,
MP00013,Direct Messages,,,MP00013,,,,,,,,,,,,,,,
MP00014,,,,MP00014,,,,,,,,,,,,,,,
MP00015,Web Site Traffic Growth,,,MP00015,,,,,,,,,,,,,,,
MP00016,Search Engine Ranking,,,MP00016,,,,,,,,,,,,,,,
MP00017,Mobile App Downloads,,,MP00017,,,,,,,,,,,,,,,
MP00018,SMS/Push Notification List,,,MP00018,,,,,,,,,,,,,,,
MP00019,,,,MP00019,,,,,,,,,,,,,,,
MP00020,Audience Demographics,,,MP00020,,,,,,,,,,,,,,,
MP00021,Audience Mentions,,,MP00021,,,,,,,,,,,,,,,
MP00022,,,,MP00022,,,,,,,,,,,,,,,
MP00023,,,,MP00023,,,,,,,,,,,,,,,
MP00024,,,,MP00024,,,,,,,,,,,,,,,
MP00025,Ad Conversions,,,MP00025,,,,,,,,,,,,,,,
MP00026,,,,MP00026,,,,,,,,,,,,,,,
MP00027,,,,MP00027,,,,,,,,,,,,,,,
MP00028,,,,MP00028,,,,,,,,,,,,,,,
MP00029,,,,MP00029,,,,,,,,,,,,,,,
MP00030,Adversary intelligence system fails to detect,,,MP00030,,,,,,,,,,,,,,,
MP00031,,,,MP00031,,,,,,,,,,,,,,,
MP00032,Email List,,,MP00032,,,,,,,,,,,,,,,
MP00033,Email Open Rate,,,MP00033,,,,,,,,,,,,,,,
MP00034,Email Click-Through Rate,,,MP00034,,,,,,,,,,,,,,,
ME00001,,,,ME00001,,,,,,,,T0008 - Create fake or imposter news sites,,,,,,,
ME00002,,,,ME00002,,,,,,,,T0009 - Create fake experts,,,,,,,
ME00003,,,,ME00003,,,,,,,,T0009 - Create fake experts,,,,,,,
ME00004,,,,ME00004,,,,,,,,T0029 - Manipulate online polls,,,,,,,
